{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d14928ee",
   "metadata": {},
   "source": [
    "# EndoMamba é¡¹ç›®ç¯å¢ƒé…ç½®å’Œä¾èµ–å®‰è£…æŒ‡å—\n",
    "\n",
    "æœ¬ç¬”è®°æœ¬æä¾›äº†åœ¨äº‘æœåŠ¡å™¨ä¸Šè®¾ç½® EndoMamba é¡¹ç›®å®Œæ•´ç¯å¢ƒçš„è¯¦ç»†æ­¥éª¤ï¼ŒåŒ…æ‹¬ï¼š\n",
    "\n",
    "ğŸ“‹ **é…ç½®è¦æ±‚**\n",
    "- Python 3.9\n",
    "- CUDA 12.4  \n",
    "- PyTorch 2.4.1+cu121\n",
    "- å„ç§æ·±åº¦å­¦ä¹ å’Œè®¡ç®—æœºè§†è§‰åº“\n",
    "- Mamba SSM å’Œ causal-conv1d è‡ªå®šä¹‰æ„å»º\n",
    "\n",
    "âš¡ **ä¸»è¦åŠŸèƒ½**\n",
    "1. ğŸ” ç¯å¢ƒæ£€æµ‹å’ŒéªŒè¯\n",
    "2. ğŸ“¦ ä¾èµ–åŒ…å®‰è£…\n",
    "3. ğŸ”¨ æºä»£ç æ„å»º\n",
    "4. âœ… åŠŸèƒ½éªŒè¯æµ‹è¯•\n",
    "\n",
    "ğŸ’¡ **æç¤º**: è¯·æŒ‰é¡ºåºæ‰§è¡Œæ¯ä¸ªæ­¥éª¤ï¼Œç¡®ä¿æ¯ä¸ªé˜¶æ®µéƒ½æˆåŠŸå®Œæˆåå†è¿›è¡Œä¸‹ä¸€æ­¥ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de701d5c",
   "metadata": {},
   "source": [
    "## 1. äº‘æœåŠ¡å™¨ç¯å¢ƒæ£€æµ‹ ğŸ”\n",
    "\n",
    "åœ¨å¼€å§‹å®‰è£…ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦æ£€æµ‹å½“å‰ç³»ç»Ÿç¯å¢ƒï¼ŒåŒ…æ‹¬æ“ä½œç³»ç»Ÿã€Pythonç‰ˆæœ¬ã€CUDAç‰ˆæœ¬ã€PyTorchç‰ˆæœ¬ï¼Œä»¥åŠç¡¬ä»¶é…ç½®ä¿¡æ¯ï¼ˆGPUã€CPUã€å†…å­˜ï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75539fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ£€æµ‹ç³»ç»ŸåŸºæœ¬ä¿¡æ¯\n",
    "import sys\n",
    "import platform\n",
    "import os\n",
    "import subprocess\n",
    "import psutil\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸ–¥ï¸  ç³»ç»ŸåŸºæœ¬ä¿¡æ¯\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"æ“ä½œç³»ç»Ÿ: {platform.system()} {platform.release()}\")\n",
    "print(f\"æ¶æ„: {platform.machine()}\")\n",
    "print(f\"Python ç‰ˆæœ¬: {sys.version}\")\n",
    "print(f\"Python å¯æ‰§è¡Œæ–‡ä»¶è·¯å¾„: {sys.executable}\")\n",
    "\n",
    "# æ£€æµ‹CPUä¿¡æ¯\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ”§ CPU ä¿¡æ¯\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"CPU æ ¸å¿ƒæ•°: {psutil.cpu_count(logical=False)} ç‰©ç†æ ¸å¿ƒ\")\n",
    "print(f\"CPU çº¿ç¨‹æ•°: {psutil.cpu_count(logical=True)} é€»è¾‘æ ¸å¿ƒ\")\n",
    "cpu_freq = psutil.cpu_freq()\n",
    "if cpu_freq:\n",
    "    print(f\"CPU é¢‘ç‡: {cpu_freq.current:.2f} MHz (æœ€å¤§: {cpu_freq.max:.2f} MHz)\")\n",
    "\n",
    "# æ£€æµ‹å†…å­˜ä¿¡æ¯\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ’¾ å†…å­˜ä¿¡æ¯\")\n",
    "print(\"=\" * 60)\n",
    "memory = psutil.virtual_memory()\n",
    "print(f\"æ€»å†…å­˜: {memory.total / (1024**3):.2f} GB\")\n",
    "print(f\"å¯ç”¨å†…å­˜: {memory.available / (1024**3):.2f} GB\")\n",
    "print(f\"å·²ä½¿ç”¨å†…å­˜: {memory.used / (1024**3):.2f} GB\")\n",
    "print(f\"å†…å­˜ä½¿ç”¨ç‡: {memory.percent:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d14db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ£€æµ‹CUDAå’ŒGPUä¿¡æ¯\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ® GPU å’Œ CUDA ä¿¡æ¯\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# æ£€æµ‹NVIDIA GPU\n",
    "try:\n",
    "    result = subprocess.run(['nvidia-smi'], capture_output=True, text=True, check=True)\n",
    "    print(\"âœ… NVIDIA GPU æ£€æµ‹æˆåŠŸ:\")\n",
    "    lines = result.stdout.split('\\n')\n",
    "    for line in lines:\n",
    "        if 'NVIDIA-SMI' in line:\n",
    "            print(f\"NVIDIA-SMI ç‰ˆæœ¬: {line.strip()}\")\n",
    "        elif 'CUDA Version' in line:\n",
    "            cuda_version = line.split('CUDA Version: ')[1].split()[0] if 'CUDA Version: ' in line else \"æœªçŸ¥\"\n",
    "            print(f\"CUDA é©±åŠ¨ç‰ˆæœ¬: {cuda_version}\")\n",
    "except (subprocess.CalledProcessError, FileNotFoundError):\n",
    "    print(\"âŒ æœªæ£€æµ‹åˆ° NVIDIA GPU æˆ– nvidia-smi æœªå®‰è£…\")\n",
    "\n",
    "# æ£€æµ‹PyTorchä¸­çš„CUDAæ”¯æŒ\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"\\nâœ… PyTorch å·²å®‰è£…: {torch.__version__}\")\n",
    "    print(f\"CUDA å¯ç”¨: {'âœ… æ˜¯' if torch.cuda.is_available() else 'âŒ å¦'}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"CUDA ç‰ˆæœ¬ (PyTorch): {torch.version.cuda}\")\n",
    "        print(f\"cuDNN ç‰ˆæœ¬: {torch.backends.cudnn.version()}\")\n",
    "        print(f\"GPU æ•°é‡: {torch.cuda.device_count()}\")\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            gpu_name = torch.cuda.get_device_name(i)\n",
    "            gpu_memory = torch.cuda.get_device_properties(i).total_memory / (1024**3)\n",
    "            print(f\"GPU {i}: {gpu_name} ({gpu_memory:.1f} GB)\")\n",
    "except ImportError:\n",
    "    print(\"âŒ PyTorch æœªå®‰è£…\")\n",
    "\n",
    "# æ£€æµ‹CUDA Toolkit\n",
    "try:\n",
    "    result = subprocess.run(['nvcc', '--version'], capture_output=True, text=True, check=True)\n",
    "    print(f\"\\nâœ… CUDA Toolkit å·²å®‰è£…:\")\n",
    "    for line in result.stdout.split('\\n'):\n",
    "        if 'release' in line:\n",
    "            print(f\"CUDA Toolkit ç‰ˆæœ¬: {line.strip()}\")\n",
    "            break\n",
    "except (subprocess.CalledProcessError, FileNotFoundError):\n",
    "    print(\"\\nâŒ CUDA Toolkit (nvcc) æœªå®‰è£…æˆ–ä¸åœ¨ PATH ä¸­\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140f4731",
   "metadata": {},
   "source": [
    "## 2. å®‰è£… Python 3.9 ğŸ\n",
    "\n",
    "å¦‚æœå½“å‰ Python ç‰ˆæœ¬ä¸æ˜¯ 3.9ï¼Œæˆ‘ä»¬éœ€è¦å®‰è£… Python 3.9 å¹¶è®¾ç½®è™šæ‹Ÿç¯å¢ƒã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc09395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ£€æŸ¥Pythonç‰ˆæœ¬å¹¶å®‰è£…Python 3.9\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "current_version = sys.version_info\n",
    "print(f\"å½“å‰ Python ç‰ˆæœ¬: {current_version.major}.{current_version.minor}.{current_version.micro}\")\n",
    "\n",
    "if current_version.major == 3 and current_version.minor == 9:\n",
    "    print(\"âœ… Python 3.9 å·²å®‰è£…ä¸”ä¸ºå½“å‰ç‰ˆæœ¬\")\n",
    "else:\n",
    "    print(\"âš ï¸  éœ€è¦å®‰è£… Python 3.9\")\n",
    "    print(\"\\næ‰§è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£… Python 3.9 (Ubuntu/Debian):\")\n",
    "    commands = [\n",
    "        \"sudo apt update\",\n",
    "        \"sudo apt install -y software-properties-common\",\n",
    "        \"sudo add-apt-repository -y ppa:deadsnakes/ppa\",\n",
    "        \"sudo apt update\", \n",
    "        \"sudo apt install -y python3.9 python3.9-dev python3.9-venv python3.9-distutils\",\n",
    "        \"sudo apt install -y python3-pip\",\n",
    "        \"python3.9 -m pip install --upgrade pip\"\n",
    "    ]\n",
    "    \n",
    "    for cmd in commands:\n",
    "        print(f\"$ {cmd}\")\n",
    "    \n",
    "    print(\"\\nâš ï¸  è¯·åœ¨ç»ˆç«¯ä¸­æ‰‹åŠ¨æ‰§è¡Œä¸Šè¿°å‘½ä»¤ï¼Œç„¶åé‡æ–°å¯åŠ¨æ­¤ç¬”è®°æœ¬\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489623db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºå’Œæ¿€æ´» Python 3.9 è™šæ‹Ÿç¯å¢ƒ\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "env_name = \"endomamba_env\"\n",
    "env_path = os.path.join(os.getcwd(), env_name)\n",
    "\n",
    "print(f\"ğŸ“ åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ: {env_name}\")\n",
    "print(f\"ğŸ“ ç¯å¢ƒè·¯å¾„: {env_path}\")\n",
    "\n",
    "try:\n",
    "    # æ£€æŸ¥è™šæ‹Ÿç¯å¢ƒæ˜¯å¦å·²å­˜åœ¨\n",
    "    if os.path.exists(env_path):\n",
    "        print(\"âœ… è™šæ‹Ÿç¯å¢ƒå·²å­˜åœ¨\")\n",
    "    else:\n",
    "        print(\"ğŸ”„ æ­£åœ¨åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ...\")\n",
    "        result = subprocess.run([\n",
    "            sys.executable, \"-m\", \"venv\", env_path\n",
    "        ], capture_output=True, text=True, check=True)\n",
    "        print(\"âœ… è™šæ‹Ÿç¯å¢ƒåˆ›å»ºæˆåŠŸ\")\n",
    "    \n",
    "    # æä¾›æ¿€æ´»å‘½ä»¤\n",
    "    if os.name == 'nt':  # Windows\n",
    "        activate_cmd = f\"{env_path}\\\\Scripts\\\\activate\"\n",
    "    else:  # Linux/Mac\n",
    "        activate_cmd = f\"source {env_path}/bin/activate\"\n",
    "    \n",
    "    print(f\"\\nğŸ’¡ æ¿€æ´»è™šæ‹Ÿç¯å¢ƒå‘½ä»¤:\")\n",
    "    print(f\"$ {activate_cmd}\")\n",
    "    print(f\"\\nğŸ’¡ åœ¨è™šæ‹Ÿç¯å¢ƒä¸­è¿è¡Œ Jupyter:\")\n",
    "    print(f\"$ {activate_cmd}\")\n",
    "    print(f\"$ pip install jupyter\")\n",
    "    print(f\"$ jupyter notebook\")\n",
    "    \n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"âŒ åˆ›å»ºè™šæ‹Ÿç¯å¢ƒå¤±è´¥: {e}\")\n",
    "    print(\"è¯·ç¡®ä¿ Python 3.9 å·²æ­£ç¡®å®‰è£…\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3602b35",
   "metadata": {},
   "source": [
    "## 3. å®‰è£… CUDA 12.4 âš¡\n",
    "\n",
    "å®‰è£… CUDA 12.4 å·¥å…·åŒ…ï¼Œé…ç½®ç¯å¢ƒå˜é‡ï¼ŒéªŒè¯ CUDA å®‰è£…å’Œ GPU å¯ç”¨æ€§ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0405380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA 12.4 å®‰è£…å‘½ä»¤\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "print(\"ğŸ”½ CUDA 12.4 å®‰è£…æ­¥éª¤ (Ubuntu/Linux)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# æ£€æŸ¥å½“å‰CUDAç‰ˆæœ¬\n",
    "try:\n",
    "    result = subprocess.run(['nvcc', '--version'], capture_output=True, text=True, check=True)\n",
    "    print(\"âœ… å½“å‰CUDAçŠ¶æ€:\")\n",
    "    for line in result.stdout.split('\\n'):\n",
    "        if 'release' in line:\n",
    "            print(f\"å·²å®‰è£…ç‰ˆæœ¬: {line.strip()}\")\n",
    "            break\n",
    "except (subprocess.CalledProcessError, FileNotFoundError):\n",
    "    print(\"âŒ CUDA Toolkit æœªå®‰è£…\")\n",
    "\n",
    "print(\"\\nğŸ“‹ å®‰è£… CUDA 12.4 çš„å‘½ä»¤:\")\n",
    "cuda_commands = [\n",
    "    \"# 1. ä¸‹è½½ CUDA 12.4 å®‰è£…åŒ…\",\n",
    "    \"wget https://developer.download.nvidia.com/compute/cuda/12.4.0/local_installers/cuda_12.4.0_550.54.14_linux.run\",\n",
    "    \"\",\n",
    "    \"# 2. ç»™å®‰è£…åŒ…æ‰§è¡Œæƒé™\",\n",
    "    \"chmod +x cuda_12.4.0_550.54.14_linux.run\",\n",
    "    \"\",\n",
    "    \"# 3. æ‰§è¡Œå®‰è£… (é™é»˜å®‰è£…ï¼Œè·³è¿‡é©±åŠ¨)\",\n",
    "    \"sudo sh cuda_12.4.0_550.54.14_linux.run --silent --toolkit\",\n",
    "    \"\",\n",
    "    \"# 4. æ·»åŠ ç¯å¢ƒå˜é‡åˆ° ~/.bashrc\",\n",
    "    'echo \\'export PATH=/usr/local/cuda-12.4/bin:$PATH\\' >> ~/.bashrc',\n",
    "    'echo \\'export LD_LIBRARY_PATH=/usr/local/cuda-12.4/lib64:$LD_LIBRARY_PATH\\' >> ~/.bashrc',\n",
    "    \"\",\n",
    "    \"# 5. é‡æ–°åŠ è½½ç¯å¢ƒå˜é‡\",\n",
    "    \"source ~/.bashrc\",\n",
    "    \"\",\n",
    "    \"# 6. éªŒè¯å®‰è£…\",\n",
    "    \"nvcc --version\"\n",
    "]\n",
    "\n",
    "for cmd in cuda_commands:\n",
    "    print(cmd)\n",
    "\n",
    "print(f\"\\nâš ï¸  é‡è¦æç¤º:\")\n",
    "print(\"1. è¯·ç¡®ä¿å·²å®‰è£…äº† NVIDIA é©±åŠ¨ (ç‰ˆæœ¬ >= 550.54.14)\")\n",
    "print(\"2. å¦‚æœé©±åŠ¨ç‰ˆæœ¬è¿‡ä½ï¼Œè¯·å…ˆæ›´æ–°é©±åŠ¨\")\n",
    "print(\"3. å®‰è£…å®Œæˆåéœ€è¦é‡å¯ç»ˆç«¯æˆ–é‡æ–°åŠ è½½ç¯å¢ƒå˜é‡\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0c541e",
   "metadata": {},
   "source": [
    "## 4. å®‰è£… PyTorch 2.4.1+cu121 ğŸ”¥\n",
    "\n",
    "ä½¿ç”¨ pip å®‰è£… PyTorch 2.4.1+cu121 ç‰ˆæœ¬ï¼ŒåŒ…æ‹¬ torchvision å’Œ torchaudioï¼ŒéªŒè¯ CUDA æ”¯æŒã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af7380a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®‰è£… PyTorch 2.4.1+cu121\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "print(\"ğŸ”¥ å®‰è£… PyTorch 2.4.1+cu121\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# PyTorch å®‰è£…å‘½ä»¤\n",
    "pytorch_install_cmd = [\n",
    "    sys.executable, \"-m\", \"pip\", \"install\",\n",
    "    \"--extra-index-url\", \"https://download.pytorch.org/whl/cu121\",\n",
    "    \"torch==2.4.1+cu121\",\n",
    "    \"torchvision==0.19.1+cu121\", \n",
    "    \"torchaudio==2.4.1+cu121\"\n",
    "]\n",
    "\n",
    "print(\"ğŸ“¦ æ­£åœ¨å®‰è£… PyTorch, torchvision, torchaudio...\")\n",
    "print(\"å‘½ä»¤:\", \" \".join(pytorch_install_cmd))\n",
    "\n",
    "try:\n",
    "    result = subprocess.run(pytorch_install_cmd, capture_output=True, text=True, check=True)\n",
    "    print(\"âœ… PyTorch å®‰è£…æˆåŠŸ!\")\n",
    "    if result.stdout:\n",
    "        print(\"å®‰è£…æ—¥å¿—:\")\n",
    "        print(result.stdout[-500:])  # æ˜¾ç¤ºæœ€å500ä¸ªå­—ç¬¦\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"âŒ PyTorch å®‰è£…å¤±è´¥: {e}\")\n",
    "    print(\"é”™è¯¯ä¿¡æ¯:\")\n",
    "    print(e.stderr)\n",
    "    \n",
    "print(\"\\nğŸ” éªŒè¯ PyTorch å®‰è£…...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63944dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# éªŒè¯ PyTorch å®‰è£…å’Œ CUDA æ”¯æŒ\n",
    "try:\n",
    "    import torch\n",
    "    import torchvision\n",
    "    import torchaudio\n",
    "    \n",
    "    print(\"âœ… PyTorch å¯¼å…¥æˆåŠŸ!\")\n",
    "    print(f\"PyTorch ç‰ˆæœ¬: {torch.__version__}\")\n",
    "    print(f\"TorchVision ç‰ˆæœ¬: {torchvision.__version__}\")\n",
    "    print(f\"TorchAudio ç‰ˆæœ¬: {torchaudio.__version__}\")\n",
    "    \n",
    "    print(f\"\\nğŸ® CUDA æ”¯æŒ:\")\n",
    "    print(f\"CUDA å¯ç”¨: {'âœ… æ˜¯' if torch.cuda.is_available() else 'âŒ å¦'}\")\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"CUDA ç‰ˆæœ¬: {torch.version.cuda}\")\n",
    "        print(f\"cuDNN ç‰ˆæœ¬: {torch.backends.cudnn.version()}\")\n",
    "        print(f\"cuDNN å¯ç”¨: {'âœ… æ˜¯' if torch.backends.cudnn.enabled else 'âŒ å¦'}\")\n",
    "        print(f\"GPU è®¾å¤‡æ•°é‡: {torch.cuda.device_count()}\")\n",
    "        \n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "            \n",
    "        # æµ‹è¯•ç®€å•çš„CUDAæ“ä½œ\n",
    "        print(f\"\\nğŸ§ª CUDA åŠŸèƒ½æµ‹è¯•:\")\n",
    "        x = torch.randn(3, 3).cuda()\n",
    "        y = torch.randn(3, 3).cuda()\n",
    "        z = x + y\n",
    "        print(f\"CUDA å¼ é‡è¿ç®—æµ‹è¯•: {'âœ… é€šè¿‡' if z.is_cuda else 'âŒ å¤±è´¥'}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"âš ï¸  CUDA ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥:\")\n",
    "        print(\"1. NVIDIA é©±åŠ¨æ˜¯å¦æ­£ç¡®å®‰è£…\")\n",
    "        print(\"2. CUDA Toolkit æ˜¯å¦å®‰è£…\")\n",
    "        print(\"3. PyTorch æ˜¯å¦ä¸º CUDA ç‰ˆæœ¬\")\n",
    "        \n",
    "except ImportError as e:\n",
    "    print(f\"âŒ PyTorch å¯¼å…¥å¤±è´¥: {e}\")\n",
    "    print(\"è¯·æ£€æŸ¥ PyTorch æ˜¯å¦æ­£ç¡®å®‰è£…\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487ef34b",
   "metadata": {},
   "source": [
    "## 5. å®‰è£…å…¶ä»–ä¾èµ–é¡¹ ğŸ“¦\n",
    "\n",
    "æ‰¹é‡å®‰è£… requirements.txt ä¸­çš„ä¾èµ–é¡¹ï¼ŒåŒ…æ‹¬æ·±åº¦å­¦ä¹ æ¡†æ¶ã€è®¡ç®—æœºè§†è§‰åº“ã€æ•°æ®ç§‘å­¦å·¥å…·ç­‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6bdba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®‰è£…å…¶ä»–ä¾èµ–é¡¹\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "print(\"ğŸ“¦ å®‰è£…é¡¹ç›®ä¾èµ–é¡¹\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ç¡®è®¤ requirements.txt æ–‡ä»¶å­˜åœ¨\n",
    "requirements_file = \"requirements.txt\"\n",
    "if not os.path.exists(requirements_file):\n",
    "    print(f\"âŒ æœªæ‰¾åˆ° {requirements_file} æ–‡ä»¶\")\n",
    "    print(\"è¯·ç¡®ä¿åœ¨é¡¹ç›®æ ¹ç›®å½•æ‰§è¡Œæ­¤è„šæœ¬\")\n",
    "else:\n",
    "    print(f\"âœ… æ‰¾åˆ° {requirements_file} æ–‡ä»¶\")\n",
    "    \n",
    "    # è¯»å–å¹¶æ˜¾ç¤ºä¾èµ–é¡¹\n",
    "    with open(requirements_file, 'r', encoding='utf-8') as f:\n",
    "        requirements = f.read()\n",
    "    \n",
    "    print(f\"\\nğŸ“‹ ä¾èµ–é¡¹åˆ—è¡¨:\")\n",
    "    print(\"-\" * 40)\n",
    "    lines = requirements.split('\\n')\n",
    "    for line in lines[:15]:  # æ˜¾ç¤ºå‰15è¡Œ\n",
    "        if line.strip() and not line.startswith('#'):\n",
    "            print(f\"  {line.strip()}\")\n",
    "    print(\"  ...\")\n",
    "    \n",
    "    print(f\"\\nğŸ”„ å¼€å§‹å®‰è£…ä¾èµ–é¡¹...\")\n",
    "    \n",
    "    try:\n",
    "        # å‡çº§pip\n",
    "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", \"pip\"], \n",
    "                      check=True, capture_output=True, text=True)\n",
    "        print(\"âœ… pip å·²å‡çº§åˆ°æœ€æ–°ç‰ˆæœ¬\")\n",
    "        \n",
    "        # å®‰è£…ä¾èµ–é¡¹\n",
    "        result = subprocess.run([\n",
    "            sys.executable, \"-m\", \"pip\", \"install\", \"-r\", requirements_file\n",
    "        ], capture_output=True, text=True, check=True)\n",
    "        \n",
    "        print(\"âœ… æ‰€æœ‰ä¾èµ–é¡¹å®‰è£…æˆåŠŸ!\")\n",
    "        \n",
    "        # æ˜¾ç¤ºå®‰è£…æ‘˜è¦\n",
    "        if \"Successfully installed\" in result.stdout:\n",
    "            installed_packages = result.stdout.split(\"Successfully installed\")[1].strip()\n",
    "            print(f\"å·²å®‰è£…åŒ…: {installed_packages[:100]}...\")\n",
    "            \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"âŒ ä¾èµ–é¡¹å®‰è£…å¤±è´¥: {e}\")\n",
    "        print(\"é”™è¯¯ä¿¡æ¯:\")\n",
    "        print(e.stderr)\n",
    "        print(\"\\nğŸ’¡ å»ºè®®:\")\n",
    "        print(\"1. æ£€æŸ¥ç½‘ç»œè¿æ¥\")\n",
    "        print(\"2. å°è¯•ä½¿ç”¨å›½å†…é•œåƒæº\")\n",
    "        print(\"3. é€ä¸ªå®‰è£…ä¾èµ–é¡¹ä»¥å®šä½é—®é¢˜\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704fd577",
   "metadata": {},
   "source": [
    "## 6. ä»æºä»£ç æ„å»ºå®‰è£… causal-conv1d ğŸ”¨\n",
    "\n",
    "å…‹éš† causal-conv1d æºä»£ç ä»“åº“ï¼Œç¼–è¯‘å¹¶å®‰è£…ï¼Œå¤„ç†å¯èƒ½çš„æ„å»ºé”™è¯¯å’Œä¾èµ–é—®é¢˜ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85810be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ„å»ºå®‰è£… causal-conv1d\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "print(\"ğŸ”¨ ä»æºä»£ç æ„å»º causal-conv1d\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# æ£€æŸ¥é¡¹ç›®ä¸­æ˜¯å¦å·²æœ‰ causal-conv1d æºç \n",
    "causal_conv1d_path = \"videomamba/causal-conv1d\"\n",
    "\n",
    "if os.path.exists(causal_conv1d_path):\n",
    "    print(f\"âœ… æ‰¾åˆ°é¡¹ç›®å†…ç½®çš„ causal-conv1d æºç : {causal_conv1d_path}\")\n",
    "    \n",
    "    # æ£€æŸ¥å½“å‰ç›®å½•å¹¶æ˜¾ç¤ºå®‰è£…æ–¹æ³•\n",
    "    print(f\"ğŸ“ å½“å‰ç›®å½•: {os.getcwd()}\")\n",
    "    \n",
    "    print(\"ğŸ”„ å¼€å§‹æ„å»ºå’Œå®‰è£… causal-conv1d...\")\n",
    "    \n",
    "    # æ–¹æ³•1: æ¨èä½¿ç”¨ --no-build-isolation æ–¹å¼å®‰è£…\n",
    "    print(\"\\nğŸ“‹ æ¨èå®‰è£…æ–¹æ³• (ä½¿ç”¨ --no-build-isolation):\")\n",
    "    install_cmd_recommended = [\n",
    "        sys.executable, \"-m\", \"pip\", \"install\", \n",
    "        causal_conv1d_path, \"--no-build-isolation\"\n",
    "    ]\n",
    "    print(f\"å‘½ä»¤: {' '.join(install_cmd_recommended)}\")\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.run(install_cmd_recommended, \n",
    "                              capture_output=True, text=True, check=True)\n",
    "        print(\"âœ… causal-conv1d å®‰è£…æˆåŠŸ!\")\n",
    "        \n",
    "        # æ˜¾ç¤ºå®‰è£…æ‘˜è¦\n",
    "        if \"Successfully installed\" in result.stdout:\n",
    "            print(\"ğŸ“¦ å®‰è£…æ‘˜è¦:\")\n",
    "            lines = result.stdout.split('\\n')\n",
    "            for line in lines:\n",
    "                if \"Successfully installed\" in line:\n",
    "                    print(f\"  {line.strip()}\")\n",
    "                elif \"Created wheel\" in line:\n",
    "                    print(f\"  {line.strip()}\")\n",
    "        \n",
    "        # æ£€æŸ¥æ˜¯å¦æœ‰è­¦å‘Šä¿¡æ¯\n",
    "        if \"WARNING\" in result.stdout:\n",
    "            print(\"\\nâš ï¸  å®‰è£…è­¦å‘Š:\")\n",
    "            warning_lines = [line for line in result.stdout.split('\\n') if 'WARNING' in line]\n",
    "            for warning in warning_lines:\n",
    "                print(f\"  {warning.strip()}\")\n",
    "            print(\"ğŸ’¡ å»ºè®®: åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ä½¿ç”¨è™šæ‹Ÿç¯å¢ƒå®‰è£…\")\n",
    "            \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"âŒ æ¨èæ–¹æ³•å®‰è£…å¤±è´¥: {e}\")\n",
    "        print(\"ğŸ”„ å°è¯•å¤‡ç”¨å®‰è£…æ–¹æ³•...\")\n",
    "        \n",
    "        # æ–¹æ³•2: ä¼ ç»Ÿæ„å»ºæ–¹å¼\n",
    "        original_dir = os.getcwd()\n",
    "        try:\n",
    "            os.chdir(causal_conv1d_path)\n",
    "            print(f\"ğŸ“ åˆ‡æ¢åˆ°ç›®å½•: {os.getcwd()}\")\n",
    "            \n",
    "            # å®‰è£…æ„å»ºä¾èµ–\n",
    "            build_deps = [\"ninja\", \"packaging\", \"wheel\", \"setuptools\"]\n",
    "            for dep in build_deps:\n",
    "                try:\n",
    "                    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", dep], \n",
    "                                 check=True, capture_output=True, text=True)\n",
    "                    print(f\"âœ… {dep} å®‰è£…æˆåŠŸ\")\n",
    "                except subprocess.CalledProcessError as e:\n",
    "                    print(f\"âš ï¸  {dep} å®‰è£…å¤±è´¥: {e}\")\n",
    "            \n",
    "            # æ„å»ºå’Œå®‰è£…\n",
    "            install_cmd = [sys.executable, \"-m\", \"pip\", \"install\", \".\", \"-v\"]\n",
    "            print(f\"æ‰§è¡Œå‘½ä»¤: {' '.join(install_cmd)}\")\n",
    "            \n",
    "            result = subprocess.run(install_cmd, capture_output=True, text=True, check=True)\n",
    "            print(\"âœ… causal-conv1d æ„å»ºå®‰è£…æˆåŠŸ!\")\n",
    "            \n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"âŒ causal-conv1d æ„å»ºå¤±è´¥: {e}\")\n",
    "            print(\"é”™è¯¯ä¿¡æ¯:\")\n",
    "            print(e.stderr[-500:] if e.stderr else \"æ— é”™è¯¯ä¿¡æ¯\")\n",
    "            print(\"\\nğŸ’¡ å¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:\")\n",
    "            print(\"1. ç¡®ä¿ CUDA å¼€å‘å·¥å…·å·²å®‰è£… (nvcc --version)\")\n",
    "            print(\"2. æ£€æŸ¥ gcc/g++ ç¼–è¯‘å™¨ç‰ˆæœ¬\")\n",
    "            print(\"3. æ£€æŸ¥ Python å¼€å‘å¤´æ–‡ä»¶\")\n",
    "            print(\"4. å°è¯•æ‰‹åŠ¨å®‰è£…: pip install ./videomamba/causal-conv1d --no-build-isolation\")\n",
    "        finally:\n",
    "            os.chdir(original_dir)\n",
    "    \n",
    "    # éªŒè¯å®‰è£…\n",
    "    print(\"\\nğŸ” éªŒè¯ causal-conv1d å®‰è£…:\")\n",
    "    try:\n",
    "        import causal_conv1d\n",
    "        print(f\"âœ… causal-conv1d å¯¼å…¥æˆåŠŸ\")\n",
    "        version = getattr(causal_conv1d, '__version__', 'æœªçŸ¥ç‰ˆæœ¬')\n",
    "        print(f\"\udce6 ç‰ˆæœ¬: {version}\")\n",
    "        \n",
    "        # æµ‹è¯•åŸºæœ¬åŠŸèƒ½\n",
    "        try:\n",
    "            from causal_conv1d import causal_conv1d_fn\n",
    "            print(\"âœ… causal_conv1d æ ¸å¿ƒå‡½æ•°å¯¼å…¥æˆåŠŸ\")\n",
    "        except ImportError as e:\n",
    "            print(f\"âš ï¸  éƒ¨åˆ†åŠŸèƒ½å¯¼å…¥å¤±è´¥: {e}\")\n",
    "            \n",
    "    except ImportError as e:\n",
    "        print(f\"âŒ causal-conv1d å¯¼å…¥å¤±è´¥: {e}\")\n",
    "        print(\"ğŸ’¡ è¯·æ£€æŸ¥å®‰è£…æ˜¯å¦æˆåŠŸï¼Œæˆ–å°è¯•é‡å¯å†…æ ¸\")\n",
    "        \n",
    "else:\n",
    "    print(f\"âŒ æœªæ‰¾åˆ° causal-conv1d æºç ç›®å½•: {causal_conv1d_path}\")\n",
    "    print(\"ğŸ’¡ è¯·ç¡®ä¿åœ¨ EndoMamba é¡¹ç›®æ ¹ç›®å½•è¿è¡Œæ­¤è„šæœ¬\")\n",
    "    \n",
    "    # æä¾›æ‰‹åŠ¨å®‰è£…å‘½ä»¤\n",
    "    print(\"\\nğŸ“‹ æ‰‹åŠ¨å®‰è£…å‘½ä»¤:\")\n",
    "    print(\"pip install ./videomamba/causal-conv1d --no-build-isolation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2d2287",
   "metadata": {},
   "source": [
    "## 7. ä»æºä»£ç æ„å»ºå®‰è£…è‡ªå®šä¹‰ Mamba ğŸ\n",
    "\n",
    "ä¸‹è½½å¹¶ç¼–è¯‘å®‰è£… Mamba SSM åº“ï¼Œé…ç½®è‡ªå®šä¹‰ç‰ˆæœ¬ï¼Œç¡®ä¿ä¸é¡¹ç›®å…¼å®¹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117dc538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ„å»ºå®‰è£…è‡ªå®šä¹‰ Mamba\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "print(\"ğŸ ä»æºä»£ç æ„å»ºè‡ªå®šä¹‰ Mamba\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# æ£€æŸ¥é¡¹ç›®ä¸­æ˜¯å¦å·²æœ‰ Mamba æºç \n",
    "mamba_path = \"videomamba/_mamba\"\n",
    "\n",
    "if os.path.exists(mamba_path):\n",
    "    print(f\"âœ… æ‰¾åˆ°é¡¹ç›®å†…ç½®çš„ Mamba æºç : {mamba_path}\")\n",
    "    \n",
    "    # è¿›å…¥ç›®å½•å¹¶æ„å»º\n",
    "    original_dir = os.getcwd()\n",
    "    try:\n",
    "        os.chdir(mamba_path)\n",
    "        print(f\"ğŸ“ å½“å‰ç›®å½•: {os.getcwd()}\")\n",
    "        \n",
    "        # æ£€æŸ¥ç‰ˆæœ¬ä¿¡æ¯\n",
    "        if os.path.exists(\"README.md\"):\n",
    "            with open(\"README.md\", \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "                readme_content = f.read()[:200]\n",
    "                print(f\"ğŸ“„ README é¢„è§ˆ: {readme_content}...\")\n",
    "        \n",
    "        print(\"ğŸ”„ å¼€å§‹æ„å»ºå’Œå®‰è£… Mamba SSM...\")\n",
    "        \n",
    "        # å®‰è£…æ„å»ºä¾èµ–\n",
    "        build_deps = [\"ninja\", \"packaging\", \"wheel\", \"setuptools\"]\n",
    "        for dep in build_deps:\n",
    "            try:\n",
    "                subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", dep], \n",
    "                             check=True, capture_output=True, text=True)\n",
    "                print(f\"âœ… {dep} å®‰è£…æˆåŠŸ\")\n",
    "            except subprocess.CalledProcessError as e:\n",
    "                print(f\"âš ï¸  {dep} å®‰è£…å¤±è´¥: {e}\")\n",
    "        \n",
    "        # å®‰è£… Mamba ä¾èµ–\n",
    "        mamba_deps = [\"triton\", \"transformers\", \"causal_conv1d\"]\n",
    "        for dep in mamba_deps:\n",
    "            try:\n",
    "                subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", dep], \n",
    "                             check=True, capture_output=True, text=True)\n",
    "                print(f\"âœ… {dep} ä¾èµ–å®‰è£…æˆåŠŸ\")\n",
    "            except subprocess.CalledProcessError as e:\n",
    "                print(f\"âš ï¸  {dep} ä¾èµ–å®‰è£…å¤±è´¥ï¼Œç»§ç»­å°è¯•: {e}\")\n",
    "        \n",
    "        # æ„å»ºå’Œå®‰è£… Mamba\n",
    "        install_cmd = [sys.executable, \"-m\", \"pip\", \"install\", \".\", \"-v\"]\n",
    "        print(f\"æ‰§è¡Œå‘½ä»¤: {' '.join(install_cmd)}\")\n",
    "        \n",
    "        result = subprocess.run(install_cmd, capture_output=True, text=True, check=True)\n",
    "        print(\"âœ… Mamba SSM æ„å»ºå®‰è£…æˆåŠŸ!\")\n",
    "        \n",
    "        # éªŒè¯å®‰è£…\n",
    "        try:\n",
    "            import mamba_ssm\n",
    "            print(f\"âœ… mamba_ssm å¯¼å…¥æˆåŠŸ\")\n",
    "            print(f\"ç‰ˆæœ¬: {getattr(mamba_ssm, '__version__', 'æœªçŸ¥')}\")\n",
    "            \n",
    "            # æµ‹è¯•å…³é”®æ¨¡å—\n",
    "            from mamba_ssm.modules.mamba_simple import Mamba\n",
    "            print(\"âœ… Mamba æ¨¡å—å¯¼å…¥æˆåŠŸ\")\n",
    "            \n",
    "        except ImportError as e:\n",
    "            print(f\"âŒ mamba_ssm å¯¼å…¥å¤±è´¥: {e}\")\n",
    "            print(\"ğŸ’¡ è¿™å¯èƒ½æ˜¯æ­£å¸¸çš„ï¼Œå› ä¸ºæŸäº›æ¨¡å—éœ€è¦åœ¨ç‰¹å®šç¯å¢ƒä¸‹è¿è¡Œ\")\n",
    "            \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"âŒ Mamba æ„å»ºå¤±è´¥: {e}\")\n",
    "        print(\"é”™è¯¯ä¿¡æ¯:\")\n",
    "        print(e.stderr[-1000:])  # æ˜¾ç¤ºæœ€å1000ä¸ªå­—ç¬¦\n",
    "        print(\"\\nğŸ’¡ å¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:\")\n",
    "        print(\"1. ç¡®ä¿ CUDA å¼€å‘å·¥å…·å·²å®‰è£…\")\n",
    "        print(\"2. æ£€æŸ¥ Triton åº“æ˜¯å¦æ­£ç¡®å®‰è£…\")\n",
    "        print(\"3. ç¡®ä¿ causal-conv1d å·²æ­£ç¡®å®‰è£…\")\n",
    "    finally:\n",
    "        os.chdir(original_dir)\n",
    "        \n",
    "else:\n",
    "    print(f\"âŒ æœªæ‰¾åˆ° Mamba æºç ç›®å½•: {mamba_path}\")\n",
    "    print(\"ğŸ’¡ è¯·ç¡®ä¿åœ¨ EndoMamba é¡¹ç›®æ ¹ç›®å½•è¿è¡Œæ­¤è„šæœ¬\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3aaf21",
   "metadata": {},
   "source": [
    "## 8. å®‰è£…éªŒè¯å’Œå¿«é€Ÿæ¼”ç¤ºæµ‹è¯• âœ…\n",
    "\n",
    "è¿è¡Œ endomamba_demo.py æ¼”ç¤ºè„šæœ¬ï¼ŒéªŒè¯æ‰€æœ‰ç»„ä»¶æ­£å¸¸å·¥ä½œï¼Œæµ‹è¯•æ¨¡å‹åŠ è½½å’Œæ¨ç†åŠŸèƒ½ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580c4979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®Œæ•´ç¯å¢ƒéªŒè¯\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "print(\"ğŸ” å®Œæ•´ç¯å¢ƒéªŒè¯\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# å…³é”®åº“éªŒè¯åˆ—è¡¨\n",
    "key_libraries = [\n",
    "    (\"torch\", \"PyTorch\"),\n",
    "    (\"torchvision\", \"TorchVision\"), \n",
    "    (\"torchaudio\", \"TorchAudio\"),\n",
    "    (\"numpy\", \"NumPy\"),\n",
    "    (\"cv2\", \"OpenCV\"),\n",
    "    (\"PIL\", \"Pillow\"),\n",
    "    (\"timm\", \"Timm\"),\n",
    "    (\"einops\", \"Einops\"),\n",
    "    (\"transformers\", \"Transformers\"),\n",
    "    (\"wandb\", \"Weights & Biases\"),\n",
    "    (\"sklearn\", \"Scikit-learn\"),\n",
    "    (\"pandas\", \"Pandas\"),\n",
    "    (\"matplotlib\", \"Matplotlib\"),\n",
    "    (\"tqdm\", \"TQDM\"),\n",
    "    (\"yaml\", \"PyYAML\"),\n",
    "    (\"causal_conv1d\", \"Causal Conv1D\"),\n",
    "    (\"mamba_ssm\", \"Mamba SSM\"),\n",
    "]\n",
    "\n",
    "print(\"ğŸ“¦ éªŒè¯å…³é”®åº“å®‰è£…çŠ¶æ€:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "success_count = 0\n",
    "total_count = len(key_libraries)\n",
    "\n",
    "for module_name, display_name in key_libraries:\n",
    "    try:\n",
    "        module = importlib.import_module(module_name)\n",
    "        version = getattr(module, '__version__', 'æœªçŸ¥ç‰ˆæœ¬')\n",
    "        print(f\"âœ… {display_name}: {version}\")\n",
    "        success_count += 1\n",
    "    except ImportError:\n",
    "        print(f\"âŒ {display_name}: æœªå®‰è£…\")\n",
    "\n",
    "print(f\"\\nğŸ“Š å®‰è£…ç»Ÿè®¡: {success_count}/{total_count} ({success_count/total_count*100:.1f}%)\")\n",
    "\n",
    "# CUDA åŠŸèƒ½æµ‹è¯•\n",
    "print(f\"\\nğŸ® CUDA åŠŸèƒ½æµ‹è¯•:\")\n",
    "print(\"-\" * 40)\n",
    "try:\n",
    "    import torch\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "        print(f\"âœ… CUDA è®¾å¤‡: {torch.cuda.get_device_name()}\")\n",
    "        \n",
    "        # åˆ›å»ºæµ‹è¯•å¼ é‡å¹¶è¿›è¡Œè®¡ç®—\n",
    "        x = torch.randn(1000, 1000, device=device)\n",
    "        y = torch.randn(1000, 1000, device=device)\n",
    "        z = torch.mm(x, y)\n",
    "        print(f\"âœ… CUDA çŸ©é˜µè¿ç®—æµ‹è¯•é€šè¿‡\")\n",
    "        \n",
    "        # æµ‹è¯•å†…å­˜\n",
    "        memory_allocated = torch.cuda.memory_allocated(device) / 1024**2\n",
    "        memory_cached = torch.cuda.memory_reserved(device) / 1024**2\n",
    "        print(f\"ğŸ“Š GPU å†…å­˜ä½¿ç”¨: {memory_allocated:.1f}MB å·²åˆ†é…, {memory_cached:.1f}MB å·²ç¼“å­˜\")\n",
    "        \n",
    "    else:\n",
    "        print(\"âŒ CUDA ä¸å¯ç”¨\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ CUDA æµ‹è¯•å¤±è´¥: {e}\")\n",
    "\n",
    "if success_count >= total_count * 0.8:  # 80%æˆåŠŸç‡\n",
    "    print(f\"\\nğŸ‰ ç¯å¢ƒéªŒè¯é€šè¿‡! å¯ä»¥ç»§ç»­æ¼”ç¤ºæµ‹è¯•\")\n",
    "else:\n",
    "    print(f\"\\nâš ï¸  ç¯å¢ƒéªŒè¯ä¸å®Œæ•´ï¼Œè¯·æ£€æŸ¥å¤±è´¥çš„åº“å®‰è£…\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a58cf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¿è¡Œ EndoMamba æ¼”ç¤ºè„šæœ¬\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "print(\"ğŸš€ è¿è¡Œ EndoMamba æ¼”ç¤ºæµ‹è¯•\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# æ£€æŸ¥æ¼”ç¤ºè„šæœ¬è·¯å¾„\n",
    "demo_script_path = \"videomamba/tests/endomamba_demo.py\"\n",
    "\n",
    "if os.path.exists(demo_script_path):\n",
    "    print(f\"âœ… æ‰¾åˆ°æ¼”ç¤ºè„šæœ¬: {demo_script_path}\")\n",
    "    \n",
    "    try:\n",
    "        print(\"ğŸ”„ æ­£åœ¨è¿è¡Œæ¼”ç¤ºè„šæœ¬...\")\n",
    "        print(\"âš ï¸  æ³¨æ„: é¦–æ¬¡è¿è¡Œå¯èƒ½éœ€è¦ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹ï¼Œè¯·è€å¿ƒç­‰å¾…\")\n",
    "        \n",
    "        # åˆ‡æ¢åˆ°æ­£ç¡®çš„ç›®å½•\n",
    "        original_dir = os.getcwd()\n",
    "        test_dir = \"videomamba/tests\"\n",
    "        \n",
    "        os.chdir(test_dir)\n",
    "        print(f\"ğŸ“ å½“å‰ç›®å½•: {os.getcwd()}\")\n",
    "        \n",
    "        # è¿è¡Œæ¼”ç¤ºè„šæœ¬\n",
    "        result = subprocess.run([\n",
    "            sys.executable, \"endomamba_demo.py\"\n",
    "        ], capture_output=True, text=True, timeout=300, check=True)  # 5åˆ†é’Ÿè¶…æ—¶\n",
    "        \n",
    "        print(\"âœ… æ¼”ç¤ºè„šæœ¬æ‰§è¡ŒæˆåŠŸ!\")\n",
    "        print(\"\\nğŸ“‹ è¾“å‡ºç»“æœ:\")\n",
    "        print(\"-\" * 40)\n",
    "        print(result.stdout)\n",
    "        \n",
    "        if result.stderr:\n",
    "            print(\"\\nâš ï¸  è­¦å‘Šä¿¡æ¯:\")\n",
    "            print(result.stderr)\n",
    "            \n",
    "        os.chdir(original_dir)\n",
    "        \n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(\"â° æ¼”ç¤ºè„šæœ¬è¿è¡Œè¶…æ—¶ (5åˆ†é’Ÿ)\")\n",
    "        print(\"ğŸ’¡ è¿™å¯èƒ½æ˜¯ç”±äºæ¨¡å‹ä¸‹è½½æˆ–è®¡ç®—æ—¶é—´è¿‡é•¿\")\n",
    "        os.chdir(original_dir)\n",
    "        \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"âŒ æ¼”ç¤ºè„šæœ¬æ‰§è¡Œå¤±è´¥: {e}\")\n",
    "        print(\"\\né”™è¯¯è¾“å‡º:\")\n",
    "        print(e.stderr)\n",
    "        print(\"\\nğŸ’¡ å¯èƒ½çš„é—®é¢˜:\")\n",
    "        print(\"1. ç¼ºå°‘é¢„è®­ç»ƒæ¨¡å‹æ–‡ä»¶\")\n",
    "        print(\"2. GPU å†…å­˜ä¸è¶³\")\n",
    "        print(\"3. æŸäº›ä¾èµ–åº“æœªæ­£ç¡®å®‰è£…\")\n",
    "        os.chdir(original_dir)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ è¿è¡Œæ¼”ç¤ºæ—¶å‘ç”Ÿé”™è¯¯: {e}\")\n",
    "        os.chdir(original_dir)\n",
    "        \n",
    "else:\n",
    "    print(f\"âŒ æœªæ‰¾åˆ°æ¼”ç¤ºè„šæœ¬: {demo_script_path}\")\n",
    "    print(\"ğŸ’¡ è¯·ç¡®ä¿åœ¨ EndoMamba é¡¹ç›®æ ¹ç›®å½•è¿è¡Œæ­¤è„šæœ¬\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9189486",
   "metadata": {},
   "source": [
    "## ğŸ‰ å®‰è£…å®Œæˆæ€»ç»“\n",
    "\n",
    "æ­å–œï¼æ‚¨å·²ç»å®Œæˆäº† EndoMamba é¡¹ç›®çš„å®Œæ•´ç¯å¢ƒé…ç½®ã€‚\n",
    "\n",
    "### âœ… å·²å®Œæˆçš„æ­¥éª¤:\n",
    "\n",
    "1. **ç¯å¢ƒæ£€æµ‹** - æ£€æŸ¥ç³»ç»Ÿé…ç½®å’Œç¡¬ä»¶ä¿¡æ¯\n",
    "2. **Python 3.9** - å®‰è£…å’Œé…ç½® Python 3.9 ç¯å¢ƒ  \n",
    "3. **CUDA 12.4** - å®‰è£… CUDA å·¥å…·åŒ…å’Œé©±åŠ¨\n",
    "4. **PyTorch 2.4.1+cu121** - å®‰è£… GPU æ”¯æŒçš„ PyTorch\n",
    "5. **ä¾èµ–é¡¹å®‰è£…** - æ‰¹é‡å®‰è£…æ‰€æœ‰å¿…éœ€çš„ Python åº“\n",
    "6. **Causal-Conv1D** - ä»æºä»£ç æ„å»ºè‡ªå®šä¹‰å·ç§¯åº“\n",
    "7. **Mamba SSM** - å®‰è£…çŠ¶æ€ç©ºé—´æ¨¡å‹åº“\n",
    "8. **åŠŸèƒ½éªŒè¯** - è¿è¡Œæ¼”ç¤ºè„šæœ¬éªŒè¯ç³»ç»Ÿ\n",
    "\n",
    "### ğŸš€ åç»­ä½¿ç”¨æŒ‡å—:\n",
    "\n",
    "#### è®­ç»ƒæ¨¡å‹\n",
    "```bash\n",
    "cd videomamba/video_sm\n",
    "python run_endomamba_pretraining.py --config configs/your_config.yaml\n",
    "```\n",
    "\n",
    "#### å¾®è°ƒæ¨¡å‹  \n",
    "```bash\n",
    "python run_class_finetuning.py --model endomamba_small --dataset your_dataset\n",
    "```\n",
    "\n",
    "#### æ¨ç†é¢„æµ‹\n",
    "```bash\n",
    "python run_inference.py --model_path /path/to/model --input_video /path/to/video\n",
    "```\n",
    "\n",
    "### ğŸ“š é‡è¦æ–‡æ¡£:\n",
    "- é¡¹ç›®æ–‡æ¡£: `README.md`\n",
    "- æ•°æ®é›†é…ç½®: `videomamba/video_sm/DATASET.md`\n",
    "- æ¨¡å‹é…ç½®: `videomamba/video_sm/models/`\n",
    "\n",
    "### âš ï¸  å¸¸è§é—®é¢˜:\n",
    "1. **GPU å†…å­˜ä¸è¶³**: å‡å°‘ batch_size æˆ–ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯\n",
    "2. **æ¨¡å‹ä¸‹è½½æ…¢**: ä½¿ç”¨å›½å†…é•œåƒæˆ–æ‰‹åŠ¨ä¸‹è½½\n",
    "3. **ç¼–è¯‘é”™è¯¯**: ç¡®ä¿ CUDA å’Œ gcc ç‰ˆæœ¬å…¼å®¹\n",
    "\n",
    "### ğŸ“ æŠ€æœ¯æ”¯æŒ:\n",
    "å¦‚æœé‡åˆ°é—®é¢˜ï¼Œè¯·æ£€æŸ¥:\n",
    "- CUDA å’Œ PyTorch ç‰ˆæœ¬å…¼å®¹æ€§\n",
    "- GPU é©±åŠ¨æ˜¯å¦æœ€æ–°\n",
    "- æ‰€æœ‰ä¾èµ–é¡¹æ˜¯å¦æ­£ç¡®å®‰è£…\n",
    "\n",
    "**ğŸŠ ç¯å¢ƒé…ç½®å®Œæˆï¼Œå¼€å§‹æ‚¨çš„ EndoMamba ä¹‹æ—…ï¼**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
