{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d14928ee",
   "metadata": {},
   "source": [
    "# EndoMamba 项目环境配置和依赖安装指南\n",
    "\n",
    "本笔记本提供了在云服务器上设置 EndoMamba 项目完整环境的详细步骤，包括：\n",
    "\n",
    "📋 **配置要求**\n",
    "- Python 3.9\n",
    "- CUDA 12.4  \n",
    "- PyTorch 2.4.1+cu121\n",
    "- 各种深度学习和计算机视觉库\n",
    "- Mamba SSM 和 causal-conv1d 自定义构建\n",
    "\n",
    "⚡ **主要功能**\n",
    "1. 🔍 环境检测和验证\n",
    "2. 📦 依赖包安装\n",
    "3. 🔨 源代码构建\n",
    "4. ✅ 功能验证测试\n",
    "\n",
    "💡 **提示**: 请按顺序执行每个步骤，确保每个阶段都成功完成后再进行下一步。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de701d5c",
   "metadata": {},
   "source": [
    "## 1. 云服务器环境检测 🔍\n",
    "\n",
    "在开始安装之前，我们需要检测当前系统环境，包括操作系统、Python版本、CUDA版本、PyTorch版本，以及硬件配置信息（GPU、CPU、内存）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75539fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "🖥️  系统基本信息\n",
      "============================================================\n",
      "操作系统: Linux 5.15.0-112-generic\n",
      "架构: x86_64\n",
      "Python 版本: 3.9.19 (main, May  6 2024, 19:43:03) \n",
      "[GCC 11.2.0]\n",
      "Python 可执行文件路径: /root/miniconda/bin/python\n",
      "\n",
      "============================================================\n",
      "🔧 CPU 信息\n",
      "============================================================\n",
      "CPU 核心数: 44 物理核心\n",
      "CPU 线程数: 88 逻辑核心\n",
      "CPU 频率: 2117.24 MHz (最大: 3700.00 MHz)\n",
      "\n",
      "============================================================\n",
      "💾 内存信息\n",
      "============================================================\n",
      "总内存: 503.08 GB\n",
      "可用内存: 445.87 GB\n",
      "已使用内存: 52.82 GB\n",
      "内存使用率: 11.4%\n"
     ]
    }
   ],
   "source": [
    "# 检测系统基本信息\n",
    "import sys\n",
    "import platform\n",
    "import os\n",
    "import subprocess\n",
    "import psutil\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"🖥️  系统基本信息\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"操作系统: {platform.system()} {platform.release()}\")\n",
    "print(f\"架构: {platform.machine()}\")\n",
    "print(f\"Python 版本: {sys.version}\")\n",
    "print(f\"Python 可执行文件路径: {sys.executable}\")\n",
    "\n",
    "# 检测CPU信息\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"🔧 CPU 信息\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"CPU 核心数: {psutil.cpu_count(logical=False)} 物理核心\")\n",
    "print(f\"CPU 线程数: {psutil.cpu_count(logical=True)} 逻辑核心\")\n",
    "cpu_freq = psutil.cpu_freq()\n",
    "if cpu_freq:\n",
    "    print(f\"CPU 频率: {cpu_freq.current:.2f} MHz (最大: {cpu_freq.max:.2f} MHz)\")\n",
    "\n",
    "# 检测内存信息\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"💾 内存信息\")\n",
    "print(\"=\" * 60)\n",
    "memory = psutil.virtual_memory()\n",
    "print(f\"总内存: {memory.total / (1024**3):.2f} GB\")\n",
    "print(f\"可用内存: {memory.available / (1024**3):.2f} GB\")\n",
    "print(f\"已使用内存: {memory.used / (1024**3):.2f} GB\")\n",
    "print(f\"内存使用率: {memory.percent:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50d14db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "🎮 GPU 和 CUDA 信息\n",
      "============================================================\n",
      "✅ NVIDIA GPU 检测成功:\n",
      "NVIDIA-SMI 版本: | NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "\n",
      "✅ PyTorch 已安装: 2.4.1+cu121\n",
      "CUDA 可用: ✅ 是\n",
      "CUDA 版本 (PyTorch): 12.1\n",
      "cuDNN 版本: 90100\n",
      "GPU 数量: 1\n",
      "GPU 0: NVIDIA GeForce RTX 4090 (23.6 GB)\n",
      "\n",
      "✅ CUDA Toolkit 已安装:\n",
      "CUDA Toolkit 版本: Cuda compilation tools, release 12.4, V12.4.131\n"
     ]
    }
   ],
   "source": [
    "# 检测CUDA和GPU信息\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"🎮 GPU 和 CUDA 信息\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 检测NVIDIA GPU\n",
    "try:\n",
    "    result = subprocess.run(['nvidia-smi'], capture_output=True, text=True, check=True)\n",
    "    print(\"✅ NVIDIA GPU 检测成功:\")\n",
    "    lines = result.stdout.split('\\n')\n",
    "    for line in lines:\n",
    "        if 'NVIDIA-SMI' in line:\n",
    "            print(f\"NVIDIA-SMI 版本: {line.strip()}\")\n",
    "        elif 'CUDA Version' in line:\n",
    "            cuda_version = line.split('CUDA Version: ')[1].split()[0] if 'CUDA Version: ' in line else \"未知\"\n",
    "            print(f\"CUDA 驱动版本: {cuda_version}\")\n",
    "except (subprocess.CalledProcessError, FileNotFoundError):\n",
    "    print(\"❌ 未检测到 NVIDIA GPU 或 nvidia-smi 未安装\")\n",
    "\n",
    "# 检测PyTorch中的CUDA支持\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"\\n✅ PyTorch 已安装: {torch.__version__}\")\n",
    "    print(f\"CUDA 可用: {'✅ 是' if torch.cuda.is_available() else '❌ 否'}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"CUDA 版本 (PyTorch): {torch.version.cuda}\")\n",
    "        print(f\"cuDNN 版本: {torch.backends.cudnn.version()}\")\n",
    "        print(f\"GPU 数量: {torch.cuda.device_count()}\")\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            gpu_name = torch.cuda.get_device_name(i)\n",
    "            gpu_memory = torch.cuda.get_device_properties(i).total_memory / (1024**3)\n",
    "            print(f\"GPU {i}: {gpu_name} ({gpu_memory:.1f} GB)\")\n",
    "except ImportError:\n",
    "    print(\"❌ PyTorch 未安装\")\n",
    "\n",
    "# 检测CUDA Toolkit\n",
    "try:\n",
    "    result = subprocess.run(['nvcc', '--version'], capture_output=True, text=True, check=True)\n",
    "    print(f\"\\n✅ CUDA Toolkit 已安装:\")\n",
    "    for line in result.stdout.split('\\n'):\n",
    "        if 'release' in line:\n",
    "            print(f\"CUDA Toolkit 版本: {line.strip()}\")\n",
    "            break\n",
    "except (subprocess.CalledProcessError, FileNotFoundError):\n",
    "    print(\"\\n❌ CUDA Toolkit (nvcc) 未安装或不在 PATH 中\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140f4731",
   "metadata": {},
   "source": [
    "## 2. 安装 Python 3.9 🐍\n",
    "\n",
    "如果当前 Python 版本不是 3.9，我们需要安装 Python 3.9 并设置虚拟环境。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc09395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查Python版本并安装Python 3.9\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "current_version = sys.version_info\n",
    "print(f\"当前 Python 版本: {current_version.major}.{current_version.minor}.{current_version.micro}\")\n",
    "\n",
    "if current_version.major == 3 and current_version.minor == 9:\n",
    "    print(\"✅ Python 3.9 已安装且为当前版本\")\n",
    "else:\n",
    "    print(\"⚠️  需要安装 Python 3.9\")\n",
    "    print(\"\\n执行以下命令安装 Python 3.9 (Ubuntu/Debian):\")\n",
    "    commands = [\n",
    "        \"sudo apt update\",\n",
    "        \"sudo apt install -y software-properties-common\",\n",
    "        \"sudo add-apt-repository -y ppa:deadsnakes/ppa\",\n",
    "        \"sudo apt update\", \n",
    "        \"sudo apt install -y python3.9 python3.9-dev python3.9-venv python3.9-distutils\",\n",
    "        \"sudo apt install -y python3-pip\",\n",
    "        \"python3.9 -m pip install --upgrade pip\"\n",
    "    ]\n",
    "    \n",
    "    for cmd in commands:\n",
    "        print(f\"$ {cmd}\")\n",
    "    \n",
    "    print(\"\\n⚠️  请在终端中手动执行上述命令，然后重新启动此笔记本\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489623db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建和激活 Python 3.9 虚拟环境\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "env_name = \"endomamba_env\"\n",
    "env_path = os.path.join(os.getcwd(), env_name)\n",
    "\n",
    "print(f\"📁 创建虚拟环境: {env_name}\")\n",
    "print(f\"📍 环境路径: {env_path}\")\n",
    "\n",
    "try:\n",
    "    # 检查虚拟环境是否已存在\n",
    "    if os.path.exists(env_path):\n",
    "        print(\"✅ 虚拟环境已存在\")\n",
    "    else:\n",
    "        print(\"🔄 正在创建虚拟环境...\")\n",
    "        result = subprocess.run([\n",
    "            sys.executable, \"-m\", \"venv\", env_path\n",
    "        ], capture_output=True, text=True, check=True)\n",
    "        print(\"✅ 虚拟环境创建成功\")\n",
    "    \n",
    "    # 提供激活命令\n",
    "    if os.name == 'nt':  # Windows\n",
    "        activate_cmd = f\"{env_path}\\\\Scripts\\\\activate\"\n",
    "    else:  # Linux/Mac\n",
    "        activate_cmd = f\"source {env_path}/bin/activate\"\n",
    "    \n",
    "    print(f\"\\n💡 激活虚拟环境命令:\")\n",
    "    print(f\"$ {activate_cmd}\")\n",
    "    print(f\"\\n💡 在虚拟环境中运行 Jupyter:\")\n",
    "    print(f\"$ {activate_cmd}\")\n",
    "    print(f\"$ pip install jupyter\")\n",
    "    print(f\"$ jupyter notebook\")\n",
    "    \n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"❌ 创建虚拟环境失败: {e}\")\n",
    "    print(\"请确保 Python 3.9 已正确安装\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3602b35",
   "metadata": {},
   "source": [
    "## 3. 安装 CUDA 12.4 ⚡\n",
    "\n",
    "安装 CUDA 12.4 工具包，配置环境变量，验证 CUDA 安装和 GPU 可用性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0405380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA 12.4 安装命令\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "print(\"🔽 CUDA 12.4 安装步骤 (Ubuntu/Linux)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 检查当前CUDA版本\n",
    "try:\n",
    "    result = subprocess.run(['nvcc', '--version'], capture_output=True, text=True, check=True)\n",
    "    print(\"✅ 当前CUDA状态:\")\n",
    "    for line in result.stdout.split('\\n'):\n",
    "        if 'release' in line:\n",
    "            print(f\"已安装版本: {line.strip()}\")\n",
    "            break\n",
    "except (subprocess.CalledProcessError, FileNotFoundError):\n",
    "    print(\"❌ CUDA Toolkit 未安装\")\n",
    "\n",
    "print(\"\\n📋 安装 CUDA 12.4 的命令:\")\n",
    "cuda_commands = [\n",
    "    \"# 1. 下载 CUDA 12.4 安装包\",\n",
    "    \"wget https://developer.download.nvidia.com/compute/cuda/12.4.0/local_installers/cuda_12.4.0_550.54.14_linux.run\",\n",
    "    \"\",\n",
    "    \"# 2. 给安装包执行权限\",\n",
    "    \"chmod +x cuda_12.4.0_550.54.14_linux.run\",\n",
    "    \"\",\n",
    "    \"# 3. 执行安装 (静默安装，跳过驱动)\",\n",
    "    \"sudo sh cuda_12.4.0_550.54.14_linux.run --silent --toolkit\",\n",
    "    \"\",\n",
    "    \"# 4. 添加环境变量到 ~/.bashrc\",\n",
    "    'echo \\'export PATH=/usr/local/cuda-12.4/bin:$PATH\\' >> ~/.bashrc',\n",
    "    'echo \\'export LD_LIBRARY_PATH=/usr/local/cuda-12.4/lib64:$LD_LIBRARY_PATH\\' >> ~/.bashrc',\n",
    "    \"\",\n",
    "    \"# 5. 重新加载环境变量\",\n",
    "    \"source ~/.bashrc\",\n",
    "    \"\",\n",
    "    \"# 6. 验证安装\",\n",
    "    \"nvcc --version\"\n",
    "]\n",
    "\n",
    "for cmd in cuda_commands:\n",
    "    print(cmd)\n",
    "\n",
    "print(f\"\\n⚠️  重要提示:\")\n",
    "print(\"1. 请确保已安装了 NVIDIA 驱动 (版本 >= 550.54.14)\")\n",
    "print(\"2. 如果驱动版本过低，请先更新驱动\")\n",
    "print(\"3. 安装完成后需要重启终端或重新加载环境变量\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0c541e",
   "metadata": {},
   "source": [
    "## 4. 安装 PyTorch 2.4.1+cu121 🔥\n",
    "\n",
    "使用 pip 安装 PyTorch 2.4.1+cu121 版本，包括 torchvision 和 torchaudio，验证 CUDA 支持。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af7380a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安装 PyTorch 2.4.1+cu121\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "print(\"🔥 安装 PyTorch 2.4.1+cu121\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# PyTorch 安装命令\n",
    "pytorch_install_cmd = [\n",
    "    sys.executable, \"-m\", \"pip\", \"install\",\n",
    "    \"--extra-index-url\", \"https://download.pytorch.org/whl/cu121\",\n",
    "    \"torch==2.4.1+cu121\",\n",
    "    \"torchvision==0.19.1+cu121\", \n",
    "    \"torchaudio==2.4.1+cu121\"\n",
    "]\n",
    "\n",
    "print(\"📦 正在安装 PyTorch, torchvision, torchaudio...\")\n",
    "print(\"命令:\", \" \".join(pytorch_install_cmd))\n",
    "\n",
    "try:\n",
    "    result = subprocess.run(pytorch_install_cmd, capture_output=True, text=True, check=True)\n",
    "    print(\"✅ PyTorch 安装成功!\")\n",
    "    if result.stdout:\n",
    "        print(\"安装日志:\")\n",
    "        print(result.stdout[-500:])  # 显示最后500个字符\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"❌ PyTorch 安装失败: {e}\")\n",
    "    print(\"错误信息:\")\n",
    "    print(e.stderr)\n",
    "    \n",
    "print(\"\\n🔍 验证 PyTorch 安装...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63944dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ PyTorch 导入成功!\n",
      "PyTorch 版本: 2.4.1+cu121\n",
      "TorchVision 版本: 0.19.1+cu121\n",
      "TorchAudio 版本: 2.4.1+cu121\n",
      "\n",
      "🎮 CUDA 支持:\n",
      "CUDA 可用: ✅ 是\n",
      "CUDA 版本: 12.1\n",
      "cuDNN 版本: 90100\n",
      "cuDNN 启用: ✅ 是\n",
      "GPU 设备数量: 1\n",
      "GPU 0: NVIDIA GeForce RTX 4090\n",
      "\n",
      "🧪 CUDA 功能测试:\n",
      "CUDA 张量运算测试: ✅ 通过\n"
     ]
    }
   ],
   "source": [
    "# 验证 PyTorch 安装和 CUDA 支持\n",
    "try:\n",
    "    import torch\n",
    "    import torchvision\n",
    "    import torchaudio\n",
    "    \n",
    "    print(\"✅ PyTorch 导入成功!\")\n",
    "    print(f\"PyTorch 版本: {torch.__version__}\")\n",
    "    print(f\"TorchVision 版本: {torchvision.__version__}\")\n",
    "    print(f\"TorchAudio 版本: {torchaudio.__version__}\")\n",
    "    \n",
    "    print(f\"\\n🎮 CUDA 支持:\")\n",
    "    print(f\"CUDA 可用: {'✅ 是' if torch.cuda.is_available() else '❌ 否'}\")\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"CUDA 版本: {torch.version.cuda}\")\n",
    "        print(f\"cuDNN 版本: {torch.backends.cudnn.version()}\")\n",
    "        print(f\"cuDNN 启用: {'✅ 是' if torch.backends.cudnn.enabled else '❌ 否'}\")\n",
    "        print(f\"GPU 设备数量: {torch.cuda.device_count()}\")\n",
    "        \n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "            \n",
    "        # 测试简单的CUDA操作\n",
    "        print(f\"\\n🧪 CUDA 功能测试:\")\n",
    "        x = torch.randn(3, 3).cuda()\n",
    "        y = torch.randn(3, 3).cuda()\n",
    "        z = x + y\n",
    "        print(f\"CUDA 张量运算测试: {'✅ 通过' if z.is_cuda else '❌ 失败'}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"⚠️  CUDA 不可用，请检查:\")\n",
    "        print(\"1. NVIDIA 驱动是否正确安装\")\n",
    "        print(\"2. CUDA Toolkit 是否安装\")\n",
    "        print(\"3. PyTorch 是否为 CUDA 版本\")\n",
    "        \n",
    "except ImportError as e:\n",
    "    print(f\"❌ PyTorch 导入失败: {e}\")\n",
    "    print(\"请检查 PyTorch 是否正确安装\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487ef34b",
   "metadata": {},
   "source": [
    "## 5. 安装其他依赖项 📦\n",
    "\n",
    "批量安装 requirements.txt 中的依赖项，包括深度学习框架、计算机视觉库、数据科学工具等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb6bdba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 安装项目依赖项\n",
      "============================================================\n",
      "✅ 找到 requirements.txt 文件\n",
      "\n",
      "📋 依赖项列表:\n",
      "----------------------------------------\n",
      "  --extra-index-url https://download.pytorch.org/whl/cu121\n",
      "  torch==2.4.1+cu121\n",
      "  torchvision==0.19.1+cu121\n",
      "  torchaudio==2.4.1+cu121\n",
      "  timm>=0.9.7\n",
      "  einops>=0.6.1\n",
      "  transformers>=4.21.0\n",
      "  triton>=2.0.0\n",
      "  ...\n",
      "\n",
      "🔄 开始安装依赖项...\n",
      "✅ pip 已升级到最新版本\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 38\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ pip 已升级到最新版本\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# 安装依赖项\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-m\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minstall\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-r\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequirements_file\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ 所有依赖项安装成功!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# 显示安装摘要\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/subprocess.py:507\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 507\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    508\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    509\u001b[0m         process\u001b[38;5;241m.\u001b[39mkill()\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/subprocess.py:1134\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1131\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1134\u001b[0m     stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_communicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendtime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1136\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m     \u001b[38;5;66;03m# See the detailed comment in .wait().\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/subprocess.py:1995\u001b[0m, in \u001b[0;36mPopen._communicate\u001b[0;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[1;32m   1988\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timeout(endtime, orig_timeout,\n\u001b[1;32m   1989\u001b[0m                         stdout, stderr,\n\u001b[1;32m   1990\u001b[0m                         skip_check_and_raise\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1991\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(  \u001b[38;5;66;03m# Impossible :)\u001b[39;00m\n\u001b[1;32m   1992\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_check_timeout(..., skip_check_and_raise=True) \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1993\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfailed to raise TimeoutExpired.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1995\u001b[0m ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1996\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timeout(endtime, orig_timeout, stdout, stderr)\n\u001b[1;32m   1998\u001b[0m \u001b[38;5;66;03m# XXX Rewrite these to use non-blocking I/O on the file\u001b[39;00m\n\u001b[1;32m   1999\u001b[0m \u001b[38;5;66;03m# objects; they are no longer using C stdio!\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 安装其他依赖项\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "print(\"📦 安装项目依赖项\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 确认 requirements.txt 文件存在\n",
    "requirements_file = \"requirements.txt\"\n",
    "if not os.path.exists(requirements_file):\n",
    "    print(f\"❌ 未找到 {requirements_file} 文件\")\n",
    "    print(\"请确保在项目根目录执行此脚本\")\n",
    "else:\n",
    "    print(f\"✅ 找到 {requirements_file} 文件\")\n",
    "    \n",
    "    # 读取并显示依赖项\n",
    "    with open(requirements_file, 'r', encoding='utf-8') as f:\n",
    "        requirements = f.read()\n",
    "    \n",
    "    print(f\"\\n📋 依赖项列表:\")\n",
    "    print(\"-\" * 40)\n",
    "    lines = requirements.split('\\n')\n",
    "    for line in lines[:15]:  # 显示前15行\n",
    "        if line.strip() and not line.startswith('#'):\n",
    "            print(f\"  {line.strip()}\")\n",
    "    print(\"  ...\")\n",
    "    \n",
    "    print(f\"\\n🔄 开始安装依赖项...\")\n",
    "    \n",
    "    try:\n",
    "        # 升级pip\n",
    "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", \"pip\"], \n",
    "                      check=True, capture_output=True, text=True)\n",
    "        print(\"✅ pip 已升级到最新版本\")\n",
    "        \n",
    "        # 安装依赖项\n",
    "        result = subprocess.run([\n",
    "            sys.executable, \"-m\", \"pip\", \"install\", \"-r\", requirements_file\n",
    "        ], capture_output=True, text=True, check=True)\n",
    "        \n",
    "        print(\"✅ 所有依赖项安装成功!\")\n",
    "        \n",
    "        # 显示安装摘要\n",
    "        if \"Successfully installed\" in result.stdout:\n",
    "            installed_packages = result.stdout.split(\"Successfully installed\")[1].strip()\n",
    "            print(f\"已安装包: {installed_packages[:100]}...\")\n",
    "            \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"❌ 依赖项安装失败: {e}\")\n",
    "        print(\"错误信息:\")\n",
    "        print(e.stderr)\n",
    "        print(\"\\n💡 建议:\")\n",
    "        print(\"1. 检查网络连接\")\n",
    "        print(\"2. 尝试使用国内镜像源\")\n",
    "        print(\"3. 逐个安装依赖项以定位问题\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704fd577",
   "metadata": {},
   "source": [
    "## 6. 从源代码构建安装 causal-conv1d 🔨\n",
    "\n",
    "克隆 causal-conv1d 源代码仓库，编译并安装，处理可能的构建错误和依赖问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85810be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建安装 causal-conv1d\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "print(\"🔨 从源代码构建 causal-conv1d\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 检查项目中是否已有 causal-conv1d 源码\n",
    "causal_conv1d_path = \"videomamba/causal-conv1d\"\n",
    "\n",
    "if os.path.exists(causal_conv1d_path):\n",
    "    print(f\"✅ 找到项目内置的 causal-conv1d 源码: {causal_conv1d_path}\")\n",
    "    \n",
    "    # 检查当前目录并显示安装方法\n",
    "    print(f\"📁 当前目录: {os.getcwd()}\")\n",
    "    \n",
    "    print(\"🔄 开始构建和安装 causal-conv1d...\")\n",
    "    \n",
    "    # 方法1: 推荐使用 --no-build-isolation 方式安装\n",
    "    print(\"\\n📋 推荐安装方法 (使用 --no-build-isolation):\")\n",
    "    install_cmd_recommended = [\n",
    "        sys.executable, \"-m\", \"pip\", \"install\", \n",
    "        causal_conv1d_path, \"--no-build-isolation\"\n",
    "    ]\n",
    "    print(f\"命令: {' '.join(install_cmd_recommended)}\")\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.run(install_cmd_recommended, \n",
    "                              capture_output=True, text=True, check=True)\n",
    "        print(\"✅ causal-conv1d 安装成功!\")\n",
    "        \n",
    "        # 显示安装摘要\n",
    "        if \"Successfully installed\" in result.stdout:\n",
    "            print(\"📦 安装摘要:\")\n",
    "            lines = result.stdout.split('\\n')\n",
    "            for line in lines:\n",
    "                if \"Successfully installed\" in line:\n",
    "                    print(f\"  {line.strip()}\")\n",
    "                elif \"Created wheel\" in line:\n",
    "                    print(f\"  {line.strip()}\")\n",
    "        \n",
    "        # 检查是否有警告信息\n",
    "        if \"WARNING\" in result.stdout:\n",
    "            print(\"\\n⚠️  安装警告:\")\n",
    "            warning_lines = [line for line in result.stdout.split('\\n') if 'WARNING' in line]\n",
    "            for warning in warning_lines:\n",
    "                print(f\"  {warning.strip()}\")\n",
    "            print(\"💡 建议: 在生产环境中使用虚拟环境安装\")\n",
    "            \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"❌ 推荐方法安装失败: {e}\")\n",
    "        print(\"🔄 尝试备用安装方法...\")\n",
    "        \n",
    "        # 方法2: 传统构建方式\n",
    "        original_dir = os.getcwd()\n",
    "        try:\n",
    "            os.chdir(causal_conv1d_path)\n",
    "            print(f\"📁 切换到目录: {os.getcwd()}\")\n",
    "            \n",
    "            # 安装构建依赖\n",
    "            build_deps = [\"ninja\", \"packaging\", \"wheel\", \"setuptools\"]\n",
    "            for dep in build_deps:\n",
    "                try:\n",
    "                    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", dep], \n",
    "                                 check=True, capture_output=True, text=True)\n",
    "                    print(f\"✅ {dep} 安装成功\")\n",
    "                except subprocess.CalledProcessError as e:\n",
    "                    print(f\"⚠️  {dep} 安装失败: {e}\")\n",
    "            \n",
    "            # 构建和安装\n",
    "            install_cmd = [sys.executable, \"-m\", \"pip\", \"install\", \".\", \"-v\"]\n",
    "            print(f\"执行命令: {' '.join(install_cmd)}\")\n",
    "            \n",
    "            result = subprocess.run(install_cmd, capture_output=True, text=True, check=True)\n",
    "            print(\"✅ causal-conv1d 构建安装成功!\")\n",
    "            \n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"❌ causal-conv1d 构建失败: {e}\")\n",
    "            print(\"错误信息:\")\n",
    "            print(e.stderr[-500:] if e.stderr else \"无错误信息\")\n",
    "            print(\"\\n💡 可能的解决方案:\")\n",
    "            print(\"1. 确保 CUDA 开发工具已安装 (nvcc --version)\")\n",
    "            print(\"2. 检查 gcc/g++ 编译器版本\")\n",
    "            print(\"3. 检查 Python 开发头文件\")\n",
    "            print(\"4. 尝试手动安装: pip install ./videomamba/causal-conv1d --no-build-isolation\")\n",
    "        finally:\n",
    "            os.chdir(original_dir)\n",
    "    \n",
    "    # 验证安装\n",
    "    print(\"\\n🔍 验证 causal-conv1d 安装:\")\n",
    "    try:\n",
    "        import causal_conv1d\n",
    "        print(f\"✅ causal-conv1d 导入成功\")\n",
    "        version = getattr(causal_conv1d, '__version__', '未知版本')\n",
    "        print(f\"\udce6 版本: {version}\")\n",
    "        \n",
    "        # 测试基本功能\n",
    "        try:\n",
    "            from causal_conv1d import causal_conv1d_fn\n",
    "            print(\"✅ causal_conv1d 核心函数导入成功\")\n",
    "        except ImportError as e:\n",
    "            print(f\"⚠️  部分功能导入失败: {e}\")\n",
    "            \n",
    "    except ImportError as e:\n",
    "        print(f\"❌ causal-conv1d 导入失败: {e}\")\n",
    "        print(\"💡 请检查安装是否成功，或尝试重启内核\")\n",
    "        \n",
    "else:\n",
    "    print(f\"❌ 未找到 causal-conv1d 源码目录: {causal_conv1d_path}\")\n",
    "    print(\"💡 请确保在 EndoMamba 项目根目录运行此脚本\")\n",
    "    \n",
    "    # 提供手动安装命令\n",
    "    print(\"\\n📋 手动安装命令:\")\n",
    "    print(\"pip install ./videomamba/causal-conv1d --no-build-isolation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6b1a2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 解决 causal-conv1d 安装失败问题\n",
      "============================================================\n",
      "❌ 检测到安装失败原因:\n",
      "1. 网络连接超时，无法下载预编译轮子\n",
      "2. PyTorch 版本为 2.4.1+cu121，但尝试下载 cu122 版本\n",
      "\n",
      "🛠️ 解决方案:\n",
      "\n",
      "方案 1: 强制本地编译安装\n",
      "----------------------------------------\n",
      "📁 切换到目录: /root/lanyun-tmp/EndoMamba-main/videomamba/causal-conv1d\n",
      "🔄 尝试强制本地编译...\n",
      "执行命令: /root/miniconda/bin/python -m pip install . --no-deps --force-reinstall -v\n",
      "✅ 强制本地编译安装成功!\n",
      "\n",
      "🔍 验证安装结果:\n",
      "✅ causal_conv1d 导入成功!\n",
      "版本: 1.0.0\n",
      "✅ 核心函数 causal_conv1d_fn 导入成功\n",
      "✅ 环境验证: CUDA 可用，可以进行 GPU 计算\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# 解决 causal-conv1d 安装失败问题 🔧\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "print(\"🔧 解决 causal-conv1d 安装失败问题\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"❌ 检测到安装失败原因:\")\n",
    "print(\"1. 网络连接超时，无法下载预编译轮子\")\n",
    "print(\"2. PyTorch 版本为 2.4.1+cu121，但尝试下载 cu122 版本\")\n",
    "print(\"\\n🛠️ 解决方案:\")\n",
    "\n",
    "# 解决方案 1: 强制本地编译\n",
    "print(\"\\n方案 1: 强制本地编译安装\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "causal_conv1d_path = \"videomamba/causal-conv1d\"\n",
    "if os.path.exists(causal_conv1d_path):\n",
    "    original_dir = os.getcwd()\n",
    "    try:\n",
    "        os.chdir(causal_conv1d_path)\n",
    "        print(f\"📁 切换到目录: {os.getcwd()}\")\n",
    "        \n",
    "        # 设置环境变量强制本地编译\n",
    "        env = os.environ.copy()\n",
    "        env['CAUSAL_CONV1D_FORCE_BUILD'] = '1'\n",
    "        env['FORCE_CUDA'] = '1'\n",
    "        \n",
    "        print(\"🔄 尝试强制本地编译...\")\n",
    "        install_cmd = [sys.executable, \"-m\", \"pip\", \"install\", \".\", \"--no-deps\", \"--force-reinstall\", \"-v\"]\n",
    "        print(f\"执行命令: {' '.join(install_cmd)}\")\n",
    "        \n",
    "        result = subprocess.run(install_cmd, env=env, capture_output=True, text=True, timeout=600)\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(\"✅ 强制本地编译安装成功!\")\n",
    "        else:\n",
    "            print(f\"❌ 强制编译失败，错误码: {result.returncode}\")\n",
    "            print(\"错误信息:\")\n",
    "            print(result.stderr[-1000:] if result.stderr else \"无错误信息\")\n",
    "            raise subprocess.CalledProcessError(result.returncode, install_cmd)\n",
    "            \n",
    "    except subprocess.CalledProcessError:\n",
    "        print(\"\\n方案 2: 尝试安装兼容版本\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # 方案 2: 安装兼容的预编译版本\n",
    "        try:\n",
    "            # 尝试安装 PyPI 上的标准版本\n",
    "            install_cmd_pypi = [sys.executable, \"-m\", \"pip\", \"install\", \"causal-conv1d>=1.0.0\", \"--force-reinstall\"]\n",
    "            print(f\"执行命令: {' '.join(install_cmd_pypi)}\")\n",
    "            \n",
    "            result = subprocess.run(install_cmd_pypi, capture_output=True, text=True, check=True)\n",
    "            print(\"✅ PyPI 版本安装成功!\")\n",
    "            \n",
    "        except subprocess.CalledProcessError:\n",
    "            print(\"\\n方案 3: 手动处理构建问题\")\n",
    "            print(\"-\" * 40)\n",
    "            \n",
    "            # 方案 3: 检查并修复构建环境\n",
    "            print(\"🔍 检查构建环境:\")\n",
    "            \n",
    "            # 检查 CUDA 编译器\n",
    "            try:\n",
    "                nvcc_result = subprocess.run(['nvcc', '--version'], capture_output=True, text=True, check=True)\n",
    "                print(\"✅ NVCC 可用\")\n",
    "            except (subprocess.CalledProcessError, FileNotFoundError):\n",
    "                print(\"❌ NVCC 不可用，需要安装 CUDA Toolkit\")\n",
    "            \n",
    "            # 检查 C++ 编译器\n",
    "            try:\n",
    "                gcc_result = subprocess.run(['gcc', '--version'], capture_output=True, text=True, check=True)\n",
    "                print(\"✅ GCC 可用\")\n",
    "            except (subprocess.CalledProcessError, FileNotFoundError):\n",
    "                print(\"❌ GCC 不可用，需要安装 build-essential\")\n",
    "                print(\"执行: sudo apt install build-essential\")\n",
    "            \n",
    "            # 安装必要的构建工具\n",
    "            build_tools = [\"wheel\", \"setuptools\", \"ninja\", \"packaging\"]\n",
    "            for tool in build_tools:\n",
    "                try:\n",
    "                    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", tool], \n",
    "                                 check=True, capture_output=True, text=True)\n",
    "                    print(f\"✅ {tool} 已升级\")\n",
    "                except subprocess.CalledProcessError as e:\n",
    "                    print(f\"⚠️  {tool} 升级失败: {e}\")\n",
    "                    \n",
    "    finally:\n",
    "        os.chdir(original_dir)\n",
    "\n",
    "# 验证安装\n",
    "print(\"\\n🔍 验证安装结果:\")\n",
    "try:\n",
    "    import causal_conv1d\n",
    "    print(\"✅ causal_conv1d 导入成功!\")\n",
    "    \n",
    "    # 检查版本\n",
    "    version = getattr(causal_conv1d, '__version__', '未知版本')\n",
    "    print(f\"版本: {version}\")\n",
    "    \n",
    "    # 测试核心函数\n",
    "    try:\n",
    "        from causal_conv1d import causal_conv1d_fn\n",
    "        print(\"✅ 核心函数 causal_conv1d_fn 导入成功\")\n",
    "        \n",
    "        # 简单功能测试\n",
    "        try:\n",
    "            import torch\n",
    "            if torch.cuda.is_available():\n",
    "                print(\"✅ 环境验证: CUDA 可用，可以进行 GPU 计算\")\n",
    "            else:\n",
    "                print(\"⚠️  CUDA 不可用，将使用 CPU 计算\")\n",
    "        except ImportError:\n",
    "            print(\"❌ PyTorch 导入失败\")\n",
    "            \n",
    "    except ImportError as e:\n",
    "        print(f\"⚠️  部分功能导入失败: {e}\")\n",
    "        print(\"这可能不会影响基本使用\")\n",
    "        \n",
    "except ImportError as e:\n",
    "    print(f\"❌ causal_conv1d 仍无法导入: {e}\")\n",
    "    print(\"\\n💡 额外建议:\")\n",
    "    print(\"1. 检查网络连接，尝试使用 VPN\")\n",
    "    print(\"2. 使用国内镜像源: pip install -i https://pypi.tuna.tsinghua.edu.cn/simple/\")\n",
    "    print(\"3. 手动下载预编译轮子并安装\")\n",
    "    print(\"4. 联系项目维护者获取帮助\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b486745d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 测试 causal-conv1d 基本功能\n",
      "============================================================\n",
      "📋 测试参数:\n",
      "  批次大小: 2\n",
      "  序列长度: 128\n",
      "  特征维度: 64\n",
      "  卷积宽度: 4\n",
      "🎮 使用设备: cuda\n",
      "\n",
      "📊 张量形状:\n",
      "  输入 x: torch.Size([2, 64, 128])\n",
      "  权重 weight: torch.Size([64, 4])\n",
      "  偏置 bias: torch.Size([64])\n",
      "\n",
      "🔄 执行 causal conv1d 运算...\n",
      "✅ silu 激活函数测试通过，输出形状: torch.Size([2, 64, 128])\n",
      "  ✓ 输出形状正确\n",
      "  ✓ 输出数值有效\n",
      "✅ swish 激活函数测试通过，输出形状: torch.Size([2, 64, 128])\n",
      "  ✓ 输出形状正确\n",
      "  ✓ 输出数值有效\n",
      "✅ 无激活函数测试通过，输出形状: torch.Size([2, 64, 128])\n",
      "  ✓ 输出形状正确\n",
      "  ✓ 输出数值有效\n",
      "\n",
      "⚡ 性能测试:\n",
      "  平均执行时间: 0.05 ms\n",
      "  吞吐量: 5190167 tokens/sec\n",
      "\n",
      "💾 内存使用测试:\n",
      "  测试张量大小: torch.Size([8, 512, 2048])\n",
      "  内存使用量: 64.0 MB\n",
      "\n",
      "🎉 causal-conv1d 功能测试全部通过!\n",
      "✅ 库安装正确，可以正常使用\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# 测试 causal-conv1d 基本功能 🧪\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "print(\"🧪 测试 causal-conv1d 基本功能\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    from causal_conv1d import causal_conv1d_fn\n",
    "    \n",
    "    # 设置测试参数\n",
    "    batch_size = 2\n",
    "    seq_len = 128\n",
    "    dim = 64\n",
    "    width = 4\n",
    "    \n",
    "    print(f\"📋 测试参数:\")\n",
    "    print(f\"  批次大小: {batch_size}\")\n",
    "    print(f\"  序列长度: {seq_len}\")\n",
    "    print(f\"  特征维度: {dim}\")\n",
    "    print(f\"  卷积宽度: {width}\")\n",
    "    \n",
    "    # 创建测试数据\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"🎮 使用设备: {device}\")\n",
    "    \n",
    "    # 输入张量 (batch, dim, seq_len)\n",
    "    x = torch.randn(batch_size, dim, seq_len, device=device, dtype=torch.float32)\n",
    "    \n",
    "    # 权重张量 (dim, width)\n",
    "    weight = torch.randn(dim, width, device=device, dtype=torch.float32)\n",
    "    \n",
    "    # 偏置张量 (dim,)\n",
    "    bias = torch.randn(dim, device=device, dtype=torch.float32)\n",
    "    \n",
    "    print(f\"\\n📊 张量形状:\")\n",
    "    print(f\"  输入 x: {x.shape}\")\n",
    "    print(f\"  权重 weight: {weight.shape}\")\n",
    "    print(f\"  偏置 bias: {bias.shape}\")\n",
    "    \n",
    "    # 执行 causal conv1d 操作\n",
    "    print(f\"\\n🔄 执行 causal conv1d 运算...\")\n",
    "    \n",
    "    # 测试不同的激活函数\n",
    "    activations = ['silu', 'swish', None]\n",
    "    \n",
    "    for activation in activations:\n",
    "        try:\n",
    "            if activation:\n",
    "                output = causal_conv1d_fn(x, weight, bias, activation=activation)\n",
    "                print(f\"✅ {activation} 激活函数测试通过，输出形状: {output.shape}\")\n",
    "            else:\n",
    "                output = causal_conv1d_fn(x, weight, bias)\n",
    "                print(f\"✅ 无激活函数测试通过，输出形状: {output.shape}\")\n",
    "                \n",
    "            # 验证输出的合理性\n",
    "            if output.shape == x.shape:\n",
    "                print(f\"  ✓ 输出形状正确\")\n",
    "            else:\n",
    "                print(f\"  ❌ 输出形状不匹配，期望: {x.shape}, 实际: {output.shape}\")\n",
    "                \n",
    "            # 检查输出是否包含有效数值\n",
    "            if torch.isfinite(output).all():\n",
    "                print(f\"  ✓ 输出数值有效\")\n",
    "            else:\n",
    "                print(f\"  ❌ 输出包含无效数值 (NaN/Inf)\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"❌ {activation or '无激活'} 测试失败: {e}\")\n",
    "    \n",
    "    # 性能测试\n",
    "    print(f\"\\n⚡ 性能测试:\")\n",
    "    \n",
    "    # 预热\n",
    "    for _ in range(5):\n",
    "        _ = causal_conv1d_fn(x, weight, bias)\n",
    "    \n",
    "    if device.type == 'cuda':\n",
    "        torch.cuda.synchronize()\n",
    "    \n",
    "    # 计时\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    num_iterations = 100\n",
    "    \n",
    "    for _ in range(num_iterations):\n",
    "        output = causal_conv1d_fn(x, weight, bias)\n",
    "    \n",
    "    if device.type == 'cuda':\n",
    "        torch.cuda.synchronize()\n",
    "    \n",
    "    end_time = time.time()\n",
    "    avg_time = (end_time - start_time) / num_iterations * 1000  # 毫秒\n",
    "    \n",
    "    print(f\"  平均执行时间: {avg_time:.2f} ms\")\n",
    "    print(f\"  吞吐量: {batch_size * seq_len / (avg_time / 1000):.0f} tokens/sec\")\n",
    "    \n",
    "    # 内存使用测试\n",
    "    if device.type == 'cuda':\n",
    "        memory_before = torch.cuda.memory_allocated(device) / 1024**2\n",
    "        \n",
    "        # 创建较大的张量进行测试\n",
    "        large_x = torch.randn(8, 512, 2048, device=device, dtype=torch.float32)\n",
    "        large_weight = torch.randn(512, 4, device=device, dtype=torch.float32)\n",
    "        large_bias = torch.randn(512, device=device, dtype=torch.float32)\n",
    "        \n",
    "        large_output = causal_conv1d_fn(large_x, large_weight, large_bias)\n",
    "        \n",
    "        memory_after = torch.cuda.memory_allocated(device) / 1024**2\n",
    "        memory_used = memory_after - memory_before\n",
    "        \n",
    "        print(f\"\\n💾 内存使用测试:\")\n",
    "        print(f\"  测试张量大小: {large_x.shape}\")\n",
    "        print(f\"  内存使用量: {memory_used:.1f} MB\")\n",
    "        \n",
    "        # 清理内存\n",
    "        del large_x, large_weight, large_bias, large_output\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    print(f\"\\n🎉 causal-conv1d 功能测试全部通过!\")\n",
    "    print(f\"✅ 库安装正确，可以正常使用\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ causal-conv1d 功能测试失败: {e}\")\n",
    "    print(f\"💡 可能的问题:\")\n",
    "    print(f\"1. CUDA 环境配置不正确\")\n",
    "    print(f\"2. PyTorch 版本不兼容\")\n",
    "    print(f\"3. 编译时出现问题\")\n",
    "    \n",
    "    # 提供调试信息\n",
    "    print(f\"\\n🔍 调试信息:\")\n",
    "    try:\n",
    "        import causal_conv1d\n",
    "        print(f\"causal_conv1d 版本: {getattr(causal_conv1d, '__version__', '未知')}\")\n",
    "        print(f\"causal_conv1d 路径: {causal_conv1d.__file__}\")\n",
    "    except:\n",
    "        print(\"无法获取 causal_conv1d 调试信息\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a6803e",
   "metadata": {},
   "source": [
    "### ✅ causal-conv1d 安装成功总结\n",
    "\n",
    "🎉 **安装状态**: causal-conv1d 已成功安装并通过所有测试！\n",
    "\n",
    "**解决的问题**:\n",
    "- ❌ 原始问题: 网络超时无法下载预编译轮子\n",
    "- ✅ 解决方案: 强制本地编译安装\n",
    "- ✅ 结果: 版本 1.0.0 安装成功\n",
    "\n",
    "**功能验证**:\n",
    "- ✅ 核心函数 `causal_conv1d_fn` 正常工作\n",
    "- ✅ 支持多种激活函数 (silu, swish, 无激活)\n",
    "- ✅ CUDA 加速正常运行\n",
    "- ✅ 性能表现优异 (平均 0.05ms 执行时间)\n",
    "- ✅ 内存使用合理\n",
    "\n",
    "**关键命令**:\n",
    "```bash\n",
    "# 强制本地编译安装\n",
    "cd videomamba/causal-conv1d\n",
    "pip install . --no-deps --force-reinstall -v\n",
    "```\n",
    "\n",
    "**技术细节**:\n",
    "- 设置环境变量 `CAUSAL_CONV1D_FORCE_BUILD=1` 和 `FORCE_CUDA=1`\n",
    "- 跳过依赖检查避免网络问题\n",
    "- 强制重新安装确保完整构建\n",
    "\n",
    "现在可以继续下一步：安装 Mamba SSM！"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2d2287",
   "metadata": {},
   "source": [
    "## 7. 从源代码构建安装自定义 Mamba 🐍\n",
    "\n",
    "下载并编译安装 Mamba SSM 库，配置自定义版本，确保与项目兼容。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117dc538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建安装自定义 Mamba\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "print(\"🐍 从源代码构建自定义 Mamba\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 检查项目中是否已有 Mamba 源码\n",
    "mamba_path = \"videomamba/_mamba\"\n",
    "\n",
    "if os.path.exists(mamba_path):\n",
    "    print(f\"✅ 找到项目内置的 Mamba 源码: {mamba_path}\")\n",
    "    \n",
    "    # 进入目录并构建\n",
    "    original_dir = os.getcwd()\n",
    "    try:\n",
    "        os.chdir(mamba_path)\n",
    "        print(f\"📁 当前目录: {os.getcwd()}\")\n",
    "        \n",
    "        # 检查版本信息\n",
    "        if os.path.exists(\"README.md\"):\n",
    "            with open(\"README.md\", \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "                readme_content = f.read()[:200]\n",
    "                print(f\"📄 README 预览: {readme_content}...\")\n",
    "        \n",
    "        print(\"🔄 开始构建和安装 Mamba SSM...\")\n",
    "        \n",
    "        # 安装构建依赖\n",
    "        build_deps = [\"ninja\", \"packaging\", \"wheel\", \"setuptools\"]\n",
    "        for dep in build_deps:\n",
    "            try:\n",
    "                subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", dep], \n",
    "                             check=True, capture_output=True, text=True)\n",
    "                print(f\"✅ {dep} 安装成功\")\n",
    "            except subprocess.CalledProcessError as e:\n",
    "                print(f\"⚠️  {dep} 安装失败: {e}\")\n",
    "        \n",
    "        # 安装 Mamba 依赖\n",
    "        mamba_deps = [\"triton\", \"transformers\", \"causal_conv1d\"]\n",
    "        for dep in mamba_deps:\n",
    "            try:\n",
    "                subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", dep], \n",
    "                             check=True, capture_output=True, text=True)\n",
    "                print(f\"✅ {dep} 依赖安装成功\")\n",
    "            except subprocess.CalledProcessError as e:\n",
    "                print(f\"⚠️  {dep} 依赖安装失败，继续尝试: {e}\")\n",
    "        \n",
    "        # 构建和安装 Mamba\n",
    "        install_cmd = [sys.executable, \"-m\", \"pip\", \"install\", \".\", \"-v\"]\n",
    "        print(f\"执行命令: {' '.join(install_cmd)}\")\n",
    "        \n",
    "        result = subprocess.run(install_cmd, capture_output=True, text=True, check=True)\n",
    "        print(\"✅ Mamba SSM 构建安装成功!\")\n",
    "        \n",
    "        # 验证安装\n",
    "        try:\n",
    "            import mamba_ssm\n",
    "            print(f\"✅ mamba_ssm 导入成功\")\n",
    "            print(f\"版本: {getattr(mamba_ssm, '__version__', '未知')}\")\n",
    "            \n",
    "            # 测试关键模块\n",
    "            from mamba_ssm.modules.mamba_simple import Mamba\n",
    "            print(\"✅ Mamba 模块导入成功\")\n",
    "            \n",
    "        except ImportError as e:\n",
    "            print(f\"❌ mamba_ssm 导入失败: {e}\")\n",
    "            print(\"💡 这可能是正常的，因为某些模块需要在特定环境下运行\")\n",
    "            \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"❌ Mamba 构建失败: {e}\")\n",
    "        print(\"错误信息:\")\n",
    "        print(e.stderr[-1000:])  # 显示最后1000个字符\n",
    "        print(\"\\n💡 可能的解决方案:\")\n",
    "        print(\"1. 确保 CUDA 开发工具已安装\")\n",
    "        print(\"2. 检查 Triton 库是否正确安装\")\n",
    "        print(\"3. 确保 causal-conv1d 已正确安装\")\n",
    "    finally:\n",
    "        os.chdir(original_dir)\n",
    "        \n",
    "else:\n",
    "    print(f\"❌ 未找到 Mamba 源码目录: {mamba_path}\")\n",
    "    print(\"💡 请确保在 EndoMamba 项目根目录运行此脚本\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3aaf21",
   "metadata": {},
   "source": [
    "## 8. 安装验证和快速演示测试 ✅\n",
    "\n",
    "运行 endomamba_demo.py 演示脚本，验证所有组件正常工作，测试模型加载和推理功能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580c4979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 完整环境验证\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "print(\"🔍 完整环境验证\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 关键库验证列表\n",
    "key_libraries = [\n",
    "    (\"torch\", \"PyTorch\"),\n",
    "    (\"torchvision\", \"TorchVision\"), \n",
    "    (\"torchaudio\", \"TorchAudio\"),\n",
    "    (\"numpy\", \"NumPy\"),\n",
    "    (\"cv2\", \"OpenCV\"),\n",
    "    (\"PIL\", \"Pillow\"),\n",
    "    (\"timm\", \"Timm\"),\n",
    "    (\"einops\", \"Einops\"),\n",
    "    (\"transformers\", \"Transformers\"),\n",
    "    (\"wandb\", \"Weights & Biases\"),\n",
    "    (\"sklearn\", \"Scikit-learn\"),\n",
    "    (\"pandas\", \"Pandas\"),\n",
    "    (\"matplotlib\", \"Matplotlib\"),\n",
    "    (\"tqdm\", \"TQDM\"),\n",
    "    (\"yaml\", \"PyYAML\"),\n",
    "    (\"causal_conv1d\", \"Causal Conv1D\"),\n",
    "    (\"mamba_ssm\", \"Mamba SSM\"),\n",
    "]\n",
    "\n",
    "print(\"📦 验证关键库安装状态:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "success_count = 0\n",
    "total_count = len(key_libraries)\n",
    "\n",
    "for module_name, display_name in key_libraries:\n",
    "    try:\n",
    "        module = importlib.import_module(module_name)\n",
    "        version = getattr(module, '__version__', '未知版本')\n",
    "        print(f\"✅ {display_name}: {version}\")\n",
    "        success_count += 1\n",
    "    except ImportError:\n",
    "        print(f\"❌ {display_name}: 未安装\")\n",
    "\n",
    "print(f\"\\n📊 安装统计: {success_count}/{total_count} ({success_count/total_count*100:.1f}%)\")\n",
    "\n",
    "# CUDA 功能测试\n",
    "print(f\"\\n🎮 CUDA 功能测试:\")\n",
    "print(\"-\" * 40)\n",
    "try:\n",
    "    import torch\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "        print(f\"✅ CUDA 设备: {torch.cuda.get_device_name()}\")\n",
    "        \n",
    "        # 创建测试张量并进行计算\n",
    "        x = torch.randn(1000, 1000, device=device)\n",
    "        y = torch.randn(1000, 1000, device=device)\n",
    "        z = torch.mm(x, y)\n",
    "        print(f\"✅ CUDA 矩阵运算测试通过\")\n",
    "        \n",
    "        # 测试内存\n",
    "        memory_allocated = torch.cuda.memory_allocated(device) / 1024**2\n",
    "        memory_cached = torch.cuda.memory_reserved(device) / 1024**2\n",
    "        print(f\"📊 GPU 内存使用: {memory_allocated:.1f}MB 已分配, {memory_cached:.1f}MB 已缓存\")\n",
    "        \n",
    "    else:\n",
    "        print(\"❌ CUDA 不可用\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ CUDA 测试失败: {e}\")\n",
    "\n",
    "if success_count >= total_count * 0.8:  # 80%成功率\n",
    "    print(f\"\\n🎉 环境验证通过! 可以继续演示测试\")\n",
    "else:\n",
    "    print(f\"\\n⚠️  环境验证不完整，请检查失败的库安装\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a58cf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 运行 EndoMamba 演示脚本\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "print(\"🚀 运行 EndoMamba 演示测试\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 检查演示脚本路径\n",
    "demo_script_path = \"videomamba/tests/endomamba_demo.py\"\n",
    "\n",
    "if os.path.exists(demo_script_path):\n",
    "    print(f\"✅ 找到演示脚本: {demo_script_path}\")\n",
    "    \n",
    "    try:\n",
    "        print(\"🔄 正在运行演示脚本...\")\n",
    "        print(\"⚠️  注意: 首次运行可能需要下载预训练模型，请耐心等待\")\n",
    "        \n",
    "        # 切换到正确的目录\n",
    "        original_dir = os.getcwd()\n",
    "        test_dir = \"videomamba/tests\"\n",
    "        \n",
    "        os.chdir(test_dir)\n",
    "        print(f\"📁 当前目录: {os.getcwd()}\")\n",
    "        \n",
    "        # 运行演示脚本\n",
    "        result = subprocess.run([\n",
    "            sys.executable, \"endomamba_demo.py\"\n",
    "        ], capture_output=True, text=True, timeout=300, check=True)  # 5分钟超时\n",
    "        \n",
    "        print(\"✅ 演示脚本执行成功!\")\n",
    "        print(\"\\n📋 输出结果:\")\n",
    "        print(\"-\" * 40)\n",
    "        print(result.stdout)\n",
    "        \n",
    "        if result.stderr:\n",
    "            print(\"\\n⚠️  警告信息:\")\n",
    "            print(result.stderr)\n",
    "            \n",
    "        os.chdir(original_dir)\n",
    "        \n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(\"⏰ 演示脚本运行超时 (5分钟)\")\n",
    "        print(\"💡 这可能是由于模型下载或计算时间过长\")\n",
    "        os.chdir(original_dir)\n",
    "        \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"❌ 演示脚本执行失败: {e}\")\n",
    "        print(\"\\n错误输出:\")\n",
    "        print(e.stderr)\n",
    "        print(\"\\n💡 可能的问题:\")\n",
    "        print(\"1. 缺少预训练模型文件\")\n",
    "        print(\"2. GPU 内存不足\")\n",
    "        print(\"3. 某些依赖库未正确安装\")\n",
    "        os.chdir(original_dir)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 运行演示时发生错误: {e}\")\n",
    "        os.chdir(original_dir)\n",
    "        \n",
    "else:\n",
    "    print(f\"❌ 未找到演示脚本: {demo_script_path}\")\n",
    "    print(\"💡 请确保在 EndoMamba 项目根目录运行此脚本\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9189486",
   "metadata": {},
   "source": [
    "## 🎉 安装完成总结\n",
    "\n",
    "恭喜！您已经完成了 EndoMamba 项目的完整环境配置。\n",
    "\n",
    "### ✅ 已完成的步骤:\n",
    "\n",
    "1. **环境检测** - 检查系统配置和硬件信息\n",
    "2. **Python 3.9** - 安装和配置 Python 3.9 环境  \n",
    "3. **CUDA 12.4** - 安装 CUDA 工具包和驱动\n",
    "4. **PyTorch 2.4.1+cu121** - 安装 GPU 支持的 PyTorch\n",
    "5. **依赖项安装** - 批量安装所有必需的 Python 库\n",
    "6. **Causal-Conv1D** - 从源代码构建自定义卷积库\n",
    "7. **Mamba SSM** - 安装状态空间模型库\n",
    "8. **功能验证** - 运行演示脚本验证系统\n",
    "\n",
    "### 🚀 后续使用指南:\n",
    "\n",
    "#### 训练模型\n",
    "```bash\n",
    "cd videomamba/video_sm\n",
    "python run_endomamba_pretraining.py --config configs/your_config.yaml\n",
    "```\n",
    "\n",
    "#### 微调模型  \n",
    "```bash\n",
    "python run_class_finetuning.py --model endomamba_small --dataset your_dataset\n",
    "```\n",
    "\n",
    "#### 推理预测\n",
    "```bash\n",
    "python run_inference.py --model_path /path/to/model --input_video /path/to/video\n",
    "```\n",
    "\n",
    "### 📚 重要文档:\n",
    "- 项目文档: `README.md`\n",
    "- 数据集配置: `videomamba/video_sm/DATASET.md`\n",
    "- 模型配置: `videomamba/video_sm/models/`\n",
    "\n",
    "### ⚠️  常见问题:\n",
    "1. **GPU 内存不足**: 减少 batch_size 或使用梯度累积\n",
    "2. **模型下载慢**: 使用国内镜像或手动下载\n",
    "3. **编译错误**: 确保 CUDA 和 gcc 版本兼容\n",
    "\n",
    "### 📞 技术支持:\n",
    "如果遇到问题，请检查:\n",
    "- CUDA 和 PyTorch 版本兼容性\n",
    "- GPU 驱动是否最新\n",
    "- 所有依赖项是否正确安装\n",
    "\n",
    "**🎊 环境配置完成，开始您的 EndoMamba 之旅！**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
