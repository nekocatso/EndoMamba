{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d14928ee",
   "metadata": {},
   "source": [
    "# EndoMamba é¡¹ç›®ç¯å¢ƒé…ç½®å’Œä¾èµ–å®‰è£…æŒ‡å—\n",
    "\n",
    "æœ¬ç¬”è®°æœ¬æä¾›äº†åœ¨äº‘æœåŠ¡å™¨ä¸Šè®¾ç½® EndoMamba é¡¹ç›®å®Œæ•´ç¯å¢ƒçš„è¯¦ç»†æ­¥éª¤ï¼ŒåŒ…æ‹¬ï¼š\n",
    "\n",
    "ğŸ“‹ **é…ç½®è¦æ±‚**\n",
    "- Python 3.9\n",
    "- CUDA 12.4  \n",
    "- PyTorch 2.4.1+cu121\n",
    "- å„ç§æ·±åº¦å­¦ä¹ å’Œè®¡ç®—æœºè§†è§‰åº“\n",
    "- Mamba SSM å’Œ causal-conv1d è‡ªå®šä¹‰æ„å»º\n",
    "\n",
    "âš¡ **ä¸»è¦åŠŸèƒ½**\n",
    "1. ğŸ” ç¯å¢ƒæ£€æµ‹å’ŒéªŒè¯\n",
    "2. ğŸ“¦ ä¾èµ–åŒ…å®‰è£…\n",
    "3. ğŸ”¨ æºä»£ç æ„å»º\n",
    "4. âœ… åŠŸèƒ½éªŒè¯æµ‹è¯•\n",
    "\n",
    "ğŸ’¡ **æç¤º**: è¯·æŒ‰é¡ºåºæ‰§è¡Œæ¯ä¸ªæ­¥éª¤ï¼Œç¡®ä¿æ¯ä¸ªé˜¶æ®µéƒ½æˆåŠŸå®Œæˆåå†è¿›è¡Œä¸‹ä¸€æ­¥ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de701d5c",
   "metadata": {},
   "source": [
    "## 1. äº‘æœåŠ¡å™¨ç¯å¢ƒæ£€æµ‹ ğŸ”\n",
    "\n",
    "åœ¨å¼€å§‹å®‰è£…ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦æ£€æµ‹å½“å‰ç³»ç»Ÿç¯å¢ƒï¼ŒåŒ…æ‹¬æ“ä½œç³»ç»Ÿã€Pythonç‰ˆæœ¬ã€CUDAç‰ˆæœ¬ã€PyTorchç‰ˆæœ¬ï¼Œä»¥åŠç¡¬ä»¶é…ç½®ä¿¡æ¯ï¼ˆGPUã€CPUã€å†…å­˜ï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75539fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ğŸ–¥ï¸  ç³»ç»ŸåŸºæœ¬ä¿¡æ¯\n",
      "============================================================\n",
      "æ“ä½œç³»ç»Ÿ: Linux 5.15.0-112-generic\n",
      "æ¶æ„: x86_64\n",
      "Python ç‰ˆæœ¬: 3.9.19 (main, May  6 2024, 19:43:03) \n",
      "[GCC 11.2.0]\n",
      "Python å¯æ‰§è¡Œæ–‡ä»¶è·¯å¾„: /root/miniconda/bin/python\n",
      "\n",
      "============================================================\n",
      "ğŸ”§ CPU ä¿¡æ¯\n",
      "============================================================\n",
      "CPU æ ¸å¿ƒæ•°: 44 ç‰©ç†æ ¸å¿ƒ\n",
      "CPU çº¿ç¨‹æ•°: 88 é€»è¾‘æ ¸å¿ƒ\n",
      "CPU é¢‘ç‡: 2117.24 MHz (æœ€å¤§: 3700.00 MHz)\n",
      "\n",
      "============================================================\n",
      "ğŸ’¾ å†…å­˜ä¿¡æ¯\n",
      "============================================================\n",
      "æ€»å†…å­˜: 503.08 GB\n",
      "å¯ç”¨å†…å­˜: 445.87 GB\n",
      "å·²ä½¿ç”¨å†…å­˜: 52.82 GB\n",
      "å†…å­˜ä½¿ç”¨ç‡: 11.4%\n"
     ]
    }
   ],
   "source": [
    "# æ£€æµ‹ç³»ç»ŸåŸºæœ¬ä¿¡æ¯\n",
    "import sys\n",
    "import platform\n",
    "import os\n",
    "import subprocess\n",
    "import psutil\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸ–¥ï¸  ç³»ç»ŸåŸºæœ¬ä¿¡æ¯\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"æ“ä½œç³»ç»Ÿ: {platform.system()} {platform.release()}\")\n",
    "print(f\"æ¶æ„: {platform.machine()}\")\n",
    "print(f\"Python ç‰ˆæœ¬: {sys.version}\")\n",
    "print(f\"Python å¯æ‰§è¡Œæ–‡ä»¶è·¯å¾„: {sys.executable}\")\n",
    "\n",
    "# æ£€æµ‹CPUä¿¡æ¯\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ”§ CPU ä¿¡æ¯\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"CPU æ ¸å¿ƒæ•°: {psutil.cpu_count(logical=False)} ç‰©ç†æ ¸å¿ƒ\")\n",
    "print(f\"CPU çº¿ç¨‹æ•°: {psutil.cpu_count(logical=True)} é€»è¾‘æ ¸å¿ƒ\")\n",
    "cpu_freq = psutil.cpu_freq()\n",
    "if cpu_freq:\n",
    "    print(f\"CPU é¢‘ç‡: {cpu_freq.current:.2f} MHz (æœ€å¤§: {cpu_freq.max:.2f} MHz)\")\n",
    "\n",
    "# æ£€æµ‹å†…å­˜ä¿¡æ¯\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ’¾ å†…å­˜ä¿¡æ¯\")\n",
    "print(\"=\" * 60)\n",
    "memory = psutil.virtual_memory()\n",
    "print(f\"æ€»å†…å­˜: {memory.total / (1024**3):.2f} GB\")\n",
    "print(f\"å¯ç”¨å†…å­˜: {memory.available / (1024**3):.2f} GB\")\n",
    "print(f\"å·²ä½¿ç”¨å†…å­˜: {memory.used / (1024**3):.2f} GB\")\n",
    "print(f\"å†…å­˜ä½¿ç”¨ç‡: {memory.percent:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50d14db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ğŸ® GPU å’Œ CUDA ä¿¡æ¯\n",
      "============================================================\n",
      "âœ… NVIDIA GPU æ£€æµ‹æˆåŠŸ:\n",
      "NVIDIA-SMI ç‰ˆæœ¬: | NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "\n",
      "âœ… PyTorch å·²å®‰è£…: 2.4.1+cu121\n",
      "CUDA å¯ç”¨: âœ… æ˜¯\n",
      "CUDA ç‰ˆæœ¬ (PyTorch): 12.1\n",
      "cuDNN ç‰ˆæœ¬: 90100\n",
      "GPU æ•°é‡: 1\n",
      "GPU 0: NVIDIA GeForce RTX 4090 (23.6 GB)\n",
      "\n",
      "âœ… CUDA Toolkit å·²å®‰è£…:\n",
      "CUDA Toolkit ç‰ˆæœ¬: Cuda compilation tools, release 12.4, V12.4.131\n"
     ]
    }
   ],
   "source": [
    "# æ£€æµ‹CUDAå’ŒGPUä¿¡æ¯\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ® GPU å’Œ CUDA ä¿¡æ¯\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# æ£€æµ‹NVIDIA GPU\n",
    "try:\n",
    "    result = subprocess.run(['nvidia-smi'], capture_output=True, text=True, check=True)\n",
    "    print(\"âœ… NVIDIA GPU æ£€æµ‹æˆåŠŸ:\")\n",
    "    lines = result.stdout.split('\\n')\n",
    "    for line in lines:\n",
    "        if 'NVIDIA-SMI' in line:\n",
    "            print(f\"NVIDIA-SMI ç‰ˆæœ¬: {line.strip()}\")\n",
    "        elif 'CUDA Version' in line:\n",
    "            cuda_version = line.split('CUDA Version: ')[1].split()[0] if 'CUDA Version: ' in line else \"æœªçŸ¥\"\n",
    "            print(f\"CUDA é©±åŠ¨ç‰ˆæœ¬: {cuda_version}\")\n",
    "except (subprocess.CalledProcessError, FileNotFoundError):\n",
    "    print(\"âŒ æœªæ£€æµ‹åˆ° NVIDIA GPU æˆ– nvidia-smi æœªå®‰è£…\")\n",
    "\n",
    "# æ£€æµ‹PyTorchä¸­çš„CUDAæ”¯æŒ\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"\\nâœ… PyTorch å·²å®‰è£…: {torch.__version__}\")\n",
    "    print(f\"CUDA å¯ç”¨: {'âœ… æ˜¯' if torch.cuda.is_available() else 'âŒ å¦'}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"CUDA ç‰ˆæœ¬ (PyTorch): {torch.version.cuda}\")\n",
    "        print(f\"cuDNN ç‰ˆæœ¬: {torch.backends.cudnn.version()}\")\n",
    "        print(f\"GPU æ•°é‡: {torch.cuda.device_count()}\")\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            gpu_name = torch.cuda.get_device_name(i)\n",
    "            gpu_memory = torch.cuda.get_device_properties(i).total_memory / (1024**3)\n",
    "            print(f\"GPU {i}: {gpu_name} ({gpu_memory:.1f} GB)\")\n",
    "except ImportError:\n",
    "    print(\"âŒ PyTorch æœªå®‰è£…\")\n",
    "\n",
    "# æ£€æµ‹CUDA Toolkit\n",
    "try:\n",
    "    result = subprocess.run(['nvcc', '--version'], capture_output=True, text=True, check=True)\n",
    "    print(f\"\\nâœ… CUDA Toolkit å·²å®‰è£…:\")\n",
    "    for line in result.stdout.split('\\n'):\n",
    "        if 'release' in line:\n",
    "            print(f\"CUDA Toolkit ç‰ˆæœ¬: {line.strip()}\")\n",
    "            break\n",
    "except (subprocess.CalledProcessError, FileNotFoundError):\n",
    "    print(\"\\nâŒ CUDA Toolkit (nvcc) æœªå®‰è£…æˆ–ä¸åœ¨ PATH ä¸­\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140f4731",
   "metadata": {},
   "source": [
    "## 2. å®‰è£… Python 3.9 ğŸ\n",
    "\n",
    "å¦‚æœå½“å‰ Python ç‰ˆæœ¬ä¸æ˜¯ 3.9ï¼Œæˆ‘ä»¬éœ€è¦å®‰è£… Python 3.9 å¹¶è®¾ç½®è™šæ‹Ÿç¯å¢ƒã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc09395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ£€æŸ¥Pythonç‰ˆæœ¬å¹¶å®‰è£…Python 3.9\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "current_version = sys.version_info\n",
    "print(f\"å½“å‰ Python ç‰ˆæœ¬: {current_version.major}.{current_version.minor}.{current_version.micro}\")\n",
    "\n",
    "if current_version.major == 3 and current_version.minor == 9:\n",
    "    print(\"âœ… Python 3.9 å·²å®‰è£…ä¸”ä¸ºå½“å‰ç‰ˆæœ¬\")\n",
    "else:\n",
    "    print(\"âš ï¸  éœ€è¦å®‰è£… Python 3.9\")\n",
    "    print(\"\\næ‰§è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£… Python 3.9 (Ubuntu/Debian):\")\n",
    "    commands = [\n",
    "        \"sudo apt update\",\n",
    "        \"sudo apt install -y software-properties-common\",\n",
    "        \"sudo add-apt-repository -y ppa:deadsnakes/ppa\",\n",
    "        \"sudo apt update\", \n",
    "        \"sudo apt install -y python3.9 python3.9-dev python3.9-venv python3.9-distutils\",\n",
    "        \"sudo apt install -y python3-pip\",\n",
    "        \"python3.9 -m pip install --upgrade pip\"\n",
    "    ]\n",
    "    \n",
    "    for cmd in commands:\n",
    "        print(f\"$ {cmd}\")\n",
    "    \n",
    "    print(\"\\nâš ï¸  è¯·åœ¨ç»ˆç«¯ä¸­æ‰‹åŠ¨æ‰§è¡Œä¸Šè¿°å‘½ä»¤ï¼Œç„¶åé‡æ–°å¯åŠ¨æ­¤ç¬”è®°æœ¬\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489623db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºå’Œæ¿€æ´» Python 3.9 è™šæ‹Ÿç¯å¢ƒ\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "env_name = \"endomamba_env\"\n",
    "env_path = os.path.join(os.getcwd(), env_name)\n",
    "\n",
    "print(f\"ğŸ“ åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ: {env_name}\")\n",
    "print(f\"ğŸ“ ç¯å¢ƒè·¯å¾„: {env_path}\")\n",
    "\n",
    "try:\n",
    "    # æ£€æŸ¥è™šæ‹Ÿç¯å¢ƒæ˜¯å¦å·²å­˜åœ¨\n",
    "    if os.path.exists(env_path):\n",
    "        print(\"âœ… è™šæ‹Ÿç¯å¢ƒå·²å­˜åœ¨\")\n",
    "    else:\n",
    "        print(\"ğŸ”„ æ­£åœ¨åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ...\")\n",
    "        result = subprocess.run([\n",
    "            sys.executable, \"-m\", \"venv\", env_path\n",
    "        ], capture_output=True, text=True, check=True)\n",
    "        print(\"âœ… è™šæ‹Ÿç¯å¢ƒåˆ›å»ºæˆåŠŸ\")\n",
    "    \n",
    "    # æä¾›æ¿€æ´»å‘½ä»¤\n",
    "    if os.name == 'nt':  # Windows\n",
    "        activate_cmd = f\"{env_path}\\\\Scripts\\\\activate\"\n",
    "    else:  # Linux/Mac\n",
    "        activate_cmd = f\"source {env_path}/bin/activate\"\n",
    "    \n",
    "    print(f\"\\nğŸ’¡ æ¿€æ´»è™šæ‹Ÿç¯å¢ƒå‘½ä»¤:\")\n",
    "    print(f\"$ {activate_cmd}\")\n",
    "    print(f\"\\nğŸ’¡ åœ¨è™šæ‹Ÿç¯å¢ƒä¸­è¿è¡Œ Jupyter:\")\n",
    "    print(f\"$ {activate_cmd}\")\n",
    "    print(f\"$ pip install jupyter\")\n",
    "    print(f\"$ jupyter notebook\")\n",
    "    \n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"âŒ åˆ›å»ºè™šæ‹Ÿç¯å¢ƒå¤±è´¥: {e}\")\n",
    "    print(\"è¯·ç¡®ä¿ Python 3.9 å·²æ­£ç¡®å®‰è£…\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3602b35",
   "metadata": {},
   "source": [
    "## 3. å®‰è£… CUDA 12.4 âš¡\n",
    "\n",
    "å®‰è£… CUDA 12.4 å·¥å…·åŒ…ï¼Œé…ç½®ç¯å¢ƒå˜é‡ï¼ŒéªŒè¯ CUDA å®‰è£…å’Œ GPU å¯ç”¨æ€§ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0405380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA 12.4 å®‰è£…å‘½ä»¤\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "print(\"ğŸ”½ CUDA 12.4 å®‰è£…æ­¥éª¤ (Ubuntu/Linux)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# æ£€æŸ¥å½“å‰CUDAç‰ˆæœ¬\n",
    "try:\n",
    "    result = subprocess.run(['nvcc', '--version'], capture_output=True, text=True, check=True)\n",
    "    print(\"âœ… å½“å‰CUDAçŠ¶æ€:\")\n",
    "    for line in result.stdout.split('\\n'):\n",
    "        if 'release' in line:\n",
    "            print(f\"å·²å®‰è£…ç‰ˆæœ¬: {line.strip()}\")\n",
    "            break\n",
    "except (subprocess.CalledProcessError, FileNotFoundError):\n",
    "    print(\"âŒ CUDA Toolkit æœªå®‰è£…\")\n",
    "\n",
    "print(\"\\nğŸ“‹ å®‰è£… CUDA 12.4 çš„å‘½ä»¤:\")\n",
    "cuda_commands = [\n",
    "    \"# 1. ä¸‹è½½ CUDA 12.4 å®‰è£…åŒ…\",\n",
    "    \"wget https://developer.download.nvidia.com/compute/cuda/12.4.0/local_installers/cuda_12.4.0_550.54.14_linux.run\",\n",
    "    \"\",\n",
    "    \"# 2. ç»™å®‰è£…åŒ…æ‰§è¡Œæƒé™\",\n",
    "    \"chmod +x cuda_12.4.0_550.54.14_linux.run\",\n",
    "    \"\",\n",
    "    \"# 3. æ‰§è¡Œå®‰è£… (é™é»˜å®‰è£…ï¼Œè·³è¿‡é©±åŠ¨)\",\n",
    "    \"sudo sh cuda_12.4.0_550.54.14_linux.run --silent --toolkit\",\n",
    "    \"\",\n",
    "    \"# 4. æ·»åŠ ç¯å¢ƒå˜é‡åˆ° ~/.bashrc\",\n",
    "    'echo \\'export PATH=/usr/local/cuda-12.4/bin:$PATH\\' >> ~/.bashrc',\n",
    "    'echo \\'export LD_LIBRARY_PATH=/usr/local/cuda-12.4/lib64:$LD_LIBRARY_PATH\\' >> ~/.bashrc',\n",
    "    \"\",\n",
    "    \"# 5. é‡æ–°åŠ è½½ç¯å¢ƒå˜é‡\",\n",
    "    \"source ~/.bashrc\",\n",
    "    \"\",\n",
    "    \"# 6. éªŒè¯å®‰è£…\",\n",
    "    \"nvcc --version\"\n",
    "]\n",
    "\n",
    "for cmd in cuda_commands:\n",
    "    print(cmd)\n",
    "\n",
    "print(f\"\\nâš ï¸  é‡è¦æç¤º:\")\n",
    "print(\"1. è¯·ç¡®ä¿å·²å®‰è£…äº† NVIDIA é©±åŠ¨ (ç‰ˆæœ¬ >= 550.54.14)\")\n",
    "print(\"2. å¦‚æœé©±åŠ¨ç‰ˆæœ¬è¿‡ä½ï¼Œè¯·å…ˆæ›´æ–°é©±åŠ¨\")\n",
    "print(\"3. å®‰è£…å®Œæˆåéœ€è¦é‡å¯ç»ˆç«¯æˆ–é‡æ–°åŠ è½½ç¯å¢ƒå˜é‡\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0c541e",
   "metadata": {},
   "source": [
    "## 4. å®‰è£… PyTorch 2.4.1+cu121 ğŸ”¥\n",
    "\n",
    "ä½¿ç”¨ pip å®‰è£… PyTorch 2.4.1+cu121 ç‰ˆæœ¬ï¼ŒåŒ…æ‹¬ torchvision å’Œ torchaudioï¼ŒéªŒè¯ CUDA æ”¯æŒã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af7380a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®‰è£… PyTorch 2.4.1+cu121\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "print(\"ğŸ”¥ å®‰è£… PyTorch 2.4.1+cu121\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# PyTorch å®‰è£…å‘½ä»¤\n",
    "pytorch_install_cmd = [\n",
    "    sys.executable, \"-m\", \"pip\", \"install\",\n",
    "    \"--extra-index-url\", \"https://download.pytorch.org/whl/cu121\",\n",
    "    \"torch==2.4.1+cu121\",\n",
    "    \"torchvision==0.19.1+cu121\", \n",
    "    \"torchaudio==2.4.1+cu121\"\n",
    "]\n",
    "\n",
    "print(\"ğŸ“¦ æ­£åœ¨å®‰è£… PyTorch, torchvision, torchaudio...\")\n",
    "print(\"å‘½ä»¤:\", \" \".join(pytorch_install_cmd))\n",
    "\n",
    "try:\n",
    "    result = subprocess.run(pytorch_install_cmd, capture_output=True, text=True, check=True)\n",
    "    print(\"âœ… PyTorch å®‰è£…æˆåŠŸ!\")\n",
    "    if result.stdout:\n",
    "        print(\"å®‰è£…æ—¥å¿—:\")\n",
    "        print(result.stdout[-500:])  # æ˜¾ç¤ºæœ€å500ä¸ªå­—ç¬¦\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"âŒ PyTorch å®‰è£…å¤±è´¥: {e}\")\n",
    "    print(\"é”™è¯¯ä¿¡æ¯:\")\n",
    "    print(e.stderr)\n",
    "    \n",
    "print(\"\\nğŸ” éªŒè¯ PyTorch å®‰è£…...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63944dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… PyTorch å¯¼å…¥æˆåŠŸ!\n",
      "PyTorch ç‰ˆæœ¬: 2.4.1+cu121\n",
      "TorchVision ç‰ˆæœ¬: 0.19.1+cu121\n",
      "TorchAudio ç‰ˆæœ¬: 2.4.1+cu121\n",
      "\n",
      "ğŸ® CUDA æ”¯æŒ:\n",
      "CUDA å¯ç”¨: âœ… æ˜¯\n",
      "CUDA ç‰ˆæœ¬: 12.1\n",
      "cuDNN ç‰ˆæœ¬: 90100\n",
      "cuDNN å¯ç”¨: âœ… æ˜¯\n",
      "GPU è®¾å¤‡æ•°é‡: 1\n",
      "GPU 0: NVIDIA GeForce RTX 4090\n",
      "\n",
      "ğŸ§ª CUDA åŠŸèƒ½æµ‹è¯•:\n",
      "CUDA å¼ é‡è¿ç®—æµ‹è¯•: âœ… é€šè¿‡\n"
     ]
    }
   ],
   "source": [
    "# éªŒè¯ PyTorch å®‰è£…å’Œ CUDA æ”¯æŒ\n",
    "try:\n",
    "    import torch\n",
    "    import torchvision\n",
    "    import torchaudio\n",
    "    \n",
    "    print(\"âœ… PyTorch å¯¼å…¥æˆåŠŸ!\")\n",
    "    print(f\"PyTorch ç‰ˆæœ¬: {torch.__version__}\")\n",
    "    print(f\"TorchVision ç‰ˆæœ¬: {torchvision.__version__}\")\n",
    "    print(f\"TorchAudio ç‰ˆæœ¬: {torchaudio.__version__}\")\n",
    "    \n",
    "    print(f\"\\nğŸ® CUDA æ”¯æŒ:\")\n",
    "    print(f\"CUDA å¯ç”¨: {'âœ… æ˜¯' if torch.cuda.is_available() else 'âŒ å¦'}\")\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"CUDA ç‰ˆæœ¬: {torch.version.cuda}\")\n",
    "        print(f\"cuDNN ç‰ˆæœ¬: {torch.backends.cudnn.version()}\")\n",
    "        print(f\"cuDNN å¯ç”¨: {'âœ… æ˜¯' if torch.backends.cudnn.enabled else 'âŒ å¦'}\")\n",
    "        print(f\"GPU è®¾å¤‡æ•°é‡: {torch.cuda.device_count()}\")\n",
    "        \n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "            \n",
    "        # æµ‹è¯•ç®€å•çš„CUDAæ“ä½œ\n",
    "        print(f\"\\nğŸ§ª CUDA åŠŸèƒ½æµ‹è¯•:\")\n",
    "        x = torch.randn(3, 3).cuda()\n",
    "        y = torch.randn(3, 3).cuda()\n",
    "        z = x + y\n",
    "        print(f\"CUDA å¼ é‡è¿ç®—æµ‹è¯•: {'âœ… é€šè¿‡' if z.is_cuda else 'âŒ å¤±è´¥'}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"âš ï¸  CUDA ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥:\")\n",
    "        print(\"1. NVIDIA é©±åŠ¨æ˜¯å¦æ­£ç¡®å®‰è£…\")\n",
    "        print(\"2. CUDA Toolkit æ˜¯å¦å®‰è£…\")\n",
    "        print(\"3. PyTorch æ˜¯å¦ä¸º CUDA ç‰ˆæœ¬\")\n",
    "        \n",
    "except ImportError as e:\n",
    "    print(f\"âŒ PyTorch å¯¼å…¥å¤±è´¥: {e}\")\n",
    "    print(\"è¯·æ£€æŸ¥ PyTorch æ˜¯å¦æ­£ç¡®å®‰è£…\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487ef34b",
   "metadata": {},
   "source": [
    "## 5. å®‰è£…å…¶ä»–ä¾èµ–é¡¹ ğŸ“¦\n",
    "\n",
    "æ‰¹é‡å®‰è£… requirements.txt ä¸­çš„ä¾èµ–é¡¹ï¼ŒåŒ…æ‹¬æ·±åº¦å­¦ä¹ æ¡†æ¶ã€è®¡ç®—æœºè§†è§‰åº“ã€æ•°æ®ç§‘å­¦å·¥å…·ç­‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb6bdba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ å®‰è£…é¡¹ç›®ä¾èµ–é¡¹\n",
      "============================================================\n",
      "âœ… æ‰¾åˆ° requirements.txt æ–‡ä»¶\n",
      "\n",
      "ğŸ“‹ ä¾èµ–é¡¹åˆ—è¡¨:\n",
      "----------------------------------------\n",
      "  --extra-index-url https://download.pytorch.org/whl/cu121\n",
      "  torch==2.4.1+cu121\n",
      "  torchvision==0.19.1+cu121\n",
      "  torchaudio==2.4.1+cu121\n",
      "  timm>=0.9.7\n",
      "  einops>=0.6.1\n",
      "  transformers>=4.21.0\n",
      "  triton>=2.0.0\n",
      "  ...\n",
      "\n",
      "ğŸ”„ å¼€å§‹å®‰è£…ä¾èµ–é¡¹...\n",
      "âœ… pip å·²å‡çº§åˆ°æœ€æ–°ç‰ˆæœ¬\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 38\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâœ… pip å·²å‡çº§åˆ°æœ€æ–°ç‰ˆæœ¬\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# å®‰è£…ä¾èµ–é¡¹\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-m\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minstall\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-r\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequirements_file\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâœ… æ‰€æœ‰ä¾èµ–é¡¹å®‰è£…æˆåŠŸ!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# æ˜¾ç¤ºå®‰è£…æ‘˜è¦\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/subprocess.py:507\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 507\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    508\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    509\u001b[0m         process\u001b[38;5;241m.\u001b[39mkill()\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/subprocess.py:1134\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1131\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1134\u001b[0m     stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_communicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendtime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1136\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m     \u001b[38;5;66;03m# See the detailed comment in .wait().\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/subprocess.py:1995\u001b[0m, in \u001b[0;36mPopen._communicate\u001b[0;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[1;32m   1988\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timeout(endtime, orig_timeout,\n\u001b[1;32m   1989\u001b[0m                         stdout, stderr,\n\u001b[1;32m   1990\u001b[0m                         skip_check_and_raise\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1991\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(  \u001b[38;5;66;03m# Impossible :)\u001b[39;00m\n\u001b[1;32m   1992\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_check_timeout(..., skip_check_and_raise=True) \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1993\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfailed to raise TimeoutExpired.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1995\u001b[0m ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1996\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timeout(endtime, orig_timeout, stdout, stderr)\n\u001b[1;32m   1998\u001b[0m \u001b[38;5;66;03m# XXX Rewrite these to use non-blocking I/O on the file\u001b[39;00m\n\u001b[1;32m   1999\u001b[0m \u001b[38;5;66;03m# objects; they are no longer using C stdio!\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# å®‰è£…å…¶ä»–ä¾èµ–é¡¹\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "print(\"ğŸ“¦ å®‰è£…é¡¹ç›®ä¾èµ–é¡¹\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ç¡®è®¤ requirements.txt æ–‡ä»¶å­˜åœ¨\n",
    "requirements_file = \"requirements.txt\"\n",
    "if not os.path.exists(requirements_file):\n",
    "    print(f\"âŒ æœªæ‰¾åˆ° {requirements_file} æ–‡ä»¶\")\n",
    "    print(\"è¯·ç¡®ä¿åœ¨é¡¹ç›®æ ¹ç›®å½•æ‰§è¡Œæ­¤è„šæœ¬\")\n",
    "else:\n",
    "    print(f\"âœ… æ‰¾åˆ° {requirements_file} æ–‡ä»¶\")\n",
    "    \n",
    "    # è¯»å–å¹¶æ˜¾ç¤ºä¾èµ–é¡¹\n",
    "    with open(requirements_file, 'r', encoding='utf-8') as f:\n",
    "        requirements = f.read()\n",
    "    \n",
    "    print(f\"\\nğŸ“‹ ä¾èµ–é¡¹åˆ—è¡¨:\")\n",
    "    print(\"-\" * 40)\n",
    "    lines = requirements.split('\\n')\n",
    "    for line in lines[:15]:  # æ˜¾ç¤ºå‰15è¡Œ\n",
    "        if line.strip() and not line.startswith('#'):\n",
    "            print(f\"  {line.strip()}\")\n",
    "    print(\"  ...\")\n",
    "    \n",
    "    print(f\"\\nğŸ”„ å¼€å§‹å®‰è£…ä¾èµ–é¡¹...\")\n",
    "    \n",
    "    try:\n",
    "        # å‡çº§pip\n",
    "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", \"pip\"], \n",
    "                      check=True, capture_output=True, text=True)\n",
    "        print(\"âœ… pip å·²å‡çº§åˆ°æœ€æ–°ç‰ˆæœ¬\")\n",
    "        \n",
    "        # å®‰è£…ä¾èµ–é¡¹\n",
    "        result = subprocess.run([\n",
    "            sys.executable, \"-m\", \"pip\", \"install\", \"-r\", requirements_file\n",
    "        ], capture_output=True, text=True, check=True)\n",
    "        \n",
    "        print(\"âœ… æ‰€æœ‰ä¾èµ–é¡¹å®‰è£…æˆåŠŸ!\")\n",
    "        \n",
    "        # æ˜¾ç¤ºå®‰è£…æ‘˜è¦\n",
    "        if \"Successfully installed\" in result.stdout:\n",
    "            installed_packages = result.stdout.split(\"Successfully installed\")[1].strip()\n",
    "            print(f\"å·²å®‰è£…åŒ…: {installed_packages[:100]}...\")\n",
    "            \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"âŒ ä¾èµ–é¡¹å®‰è£…å¤±è´¥: {e}\")\n",
    "        print(\"é”™è¯¯ä¿¡æ¯:\")\n",
    "        print(e.stderr)\n",
    "        print(\"\\nğŸ’¡ å»ºè®®:\")\n",
    "        print(\"1. æ£€æŸ¥ç½‘ç»œè¿æ¥\")\n",
    "        print(\"2. å°è¯•ä½¿ç”¨å›½å†…é•œåƒæº\")\n",
    "        print(\"3. é€ä¸ªå®‰è£…ä¾èµ–é¡¹ä»¥å®šä½é—®é¢˜\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704fd577",
   "metadata": {},
   "source": [
    "## 6. ä»æºä»£ç æ„å»ºå®‰è£… causal-conv1d ğŸ”¨\n",
    "\n",
    "å…‹éš† causal-conv1d æºä»£ç ä»“åº“ï¼Œç¼–è¯‘å¹¶å®‰è£…ï¼Œå¤„ç†å¯èƒ½çš„æ„å»ºé”™è¯¯å’Œä¾èµ–é—®é¢˜ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85810be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ„å»ºå®‰è£… causal-conv1d\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "print(\"ğŸ”¨ ä»æºä»£ç æ„å»º causal-conv1d\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# æ£€æŸ¥é¡¹ç›®ä¸­æ˜¯å¦å·²æœ‰ causal-conv1d æºç \n",
    "causal_conv1d_path = \"videomamba/causal-conv1d\"\n",
    "\n",
    "if os.path.exists(causal_conv1d_path):\n",
    "    print(f\"âœ… æ‰¾åˆ°é¡¹ç›®å†…ç½®çš„ causal-conv1d æºç : {causal_conv1d_path}\")\n",
    "    \n",
    "    # æ£€æŸ¥å½“å‰ç›®å½•å¹¶æ˜¾ç¤ºå®‰è£…æ–¹æ³•\n",
    "    print(f\"ğŸ“ å½“å‰ç›®å½•: {os.getcwd()}\")\n",
    "    \n",
    "    print(\"ğŸ”„ å¼€å§‹æ„å»ºå’Œå®‰è£… causal-conv1d...\")\n",
    "    \n",
    "    # æ–¹æ³•1: æ¨èä½¿ç”¨ --no-build-isolation æ–¹å¼å®‰è£…\n",
    "    print(\"\\nğŸ“‹ æ¨èå®‰è£…æ–¹æ³• (ä½¿ç”¨ --no-build-isolation):\")\n",
    "    install_cmd_recommended = [\n",
    "        sys.executable, \"-m\", \"pip\", \"install\", \n",
    "        causal_conv1d_path, \"--no-build-isolation\"\n",
    "    ]\n",
    "    print(f\"å‘½ä»¤: {' '.join(install_cmd_recommended)}\")\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.run(install_cmd_recommended, \n",
    "                              capture_output=True, text=True, check=True)\n",
    "        print(\"âœ… causal-conv1d å®‰è£…æˆåŠŸ!\")\n",
    "        \n",
    "        # æ˜¾ç¤ºå®‰è£…æ‘˜è¦\n",
    "        if \"Successfully installed\" in result.stdout:\n",
    "            print(\"ğŸ“¦ å®‰è£…æ‘˜è¦:\")\n",
    "            lines = result.stdout.split('\\n')\n",
    "            for line in lines:\n",
    "                if \"Successfully installed\" in line:\n",
    "                    print(f\"  {line.strip()}\")\n",
    "                elif \"Created wheel\" in line:\n",
    "                    print(f\"  {line.strip()}\")\n",
    "        \n",
    "        # æ£€æŸ¥æ˜¯å¦æœ‰è­¦å‘Šä¿¡æ¯\n",
    "        if \"WARNING\" in result.stdout:\n",
    "            print(\"\\nâš ï¸  å®‰è£…è­¦å‘Š:\")\n",
    "            warning_lines = [line for line in result.stdout.split('\\n') if 'WARNING' in line]\n",
    "            for warning in warning_lines:\n",
    "                print(f\"  {warning.strip()}\")\n",
    "            print(\"ğŸ’¡ å»ºè®®: åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ä½¿ç”¨è™šæ‹Ÿç¯å¢ƒå®‰è£…\")\n",
    "            \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"âŒ æ¨èæ–¹æ³•å®‰è£…å¤±è´¥: {e}\")\n",
    "        print(\"ğŸ”„ å°è¯•å¤‡ç”¨å®‰è£…æ–¹æ³•...\")\n",
    "        \n",
    "        # æ–¹æ³•2: ä¼ ç»Ÿæ„å»ºæ–¹å¼\n",
    "        original_dir = os.getcwd()\n",
    "        try:\n",
    "            os.chdir(causal_conv1d_path)\n",
    "            print(f\"ğŸ“ åˆ‡æ¢åˆ°ç›®å½•: {os.getcwd()}\")\n",
    "            \n",
    "            # å®‰è£…æ„å»ºä¾èµ–\n",
    "            build_deps = [\"ninja\", \"packaging\", \"wheel\", \"setuptools\"]\n",
    "            for dep in build_deps:\n",
    "                try:\n",
    "                    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", dep], \n",
    "                                 check=True, capture_output=True, text=True)\n",
    "                    print(f\"âœ… {dep} å®‰è£…æˆåŠŸ\")\n",
    "                except subprocess.CalledProcessError as e:\n",
    "                    print(f\"âš ï¸  {dep} å®‰è£…å¤±è´¥: {e}\")\n",
    "            \n",
    "            # æ„å»ºå’Œå®‰è£…\n",
    "            install_cmd = [sys.executable, \"-m\", \"pip\", \"install\", \".\", \"-v\"]\n",
    "            print(f\"æ‰§è¡Œå‘½ä»¤: {' '.join(install_cmd)}\")\n",
    "            \n",
    "            result = subprocess.run(install_cmd, capture_output=True, text=True, check=True)\n",
    "            print(\"âœ… causal-conv1d æ„å»ºå®‰è£…æˆåŠŸ!\")\n",
    "            \n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"âŒ causal-conv1d æ„å»ºå¤±è´¥: {e}\")\n",
    "            print(\"é”™è¯¯ä¿¡æ¯:\")\n",
    "            print(e.stderr[-500:] if e.stderr else \"æ— é”™è¯¯ä¿¡æ¯\")\n",
    "            print(\"\\nğŸ’¡ å¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:\")\n",
    "            print(\"1. ç¡®ä¿ CUDA å¼€å‘å·¥å…·å·²å®‰è£… (nvcc --version)\")\n",
    "            print(\"2. æ£€æŸ¥ gcc/g++ ç¼–è¯‘å™¨ç‰ˆæœ¬\")\n",
    "            print(\"3. æ£€æŸ¥ Python å¼€å‘å¤´æ–‡ä»¶\")\n",
    "            print(\"4. å°è¯•æ‰‹åŠ¨å®‰è£…: pip install ./videomamba/causal-conv1d --no-build-isolation\")\n",
    "        finally:\n",
    "            os.chdir(original_dir)\n",
    "    \n",
    "    # éªŒè¯å®‰è£…\n",
    "    print(\"\\nğŸ” éªŒè¯ causal-conv1d å®‰è£…:\")\n",
    "    try:\n",
    "        import causal_conv1d\n",
    "        print(f\"âœ… causal-conv1d å¯¼å…¥æˆåŠŸ\")\n",
    "        version = getattr(causal_conv1d, '__version__', 'æœªçŸ¥ç‰ˆæœ¬')\n",
    "        print(f\"\udce6 ç‰ˆæœ¬: {version}\")\n",
    "        \n",
    "        # æµ‹è¯•åŸºæœ¬åŠŸèƒ½\n",
    "        try:\n",
    "            from causal_conv1d import causal_conv1d_fn\n",
    "            print(\"âœ… causal_conv1d æ ¸å¿ƒå‡½æ•°å¯¼å…¥æˆåŠŸ\")\n",
    "        except ImportError as e:\n",
    "            print(f\"âš ï¸  éƒ¨åˆ†åŠŸèƒ½å¯¼å…¥å¤±è´¥: {e}\")\n",
    "            \n",
    "    except ImportError as e:\n",
    "        print(f\"âŒ causal-conv1d å¯¼å…¥å¤±è´¥: {e}\")\n",
    "        print(\"ğŸ’¡ è¯·æ£€æŸ¥å®‰è£…æ˜¯å¦æˆåŠŸï¼Œæˆ–å°è¯•é‡å¯å†…æ ¸\")\n",
    "        \n",
    "else:\n",
    "    print(f\"âŒ æœªæ‰¾åˆ° causal-conv1d æºç ç›®å½•: {causal_conv1d_path}\")\n",
    "    print(\"ğŸ’¡ è¯·ç¡®ä¿åœ¨ EndoMamba é¡¹ç›®æ ¹ç›®å½•è¿è¡Œæ­¤è„šæœ¬\")\n",
    "    \n",
    "    # æä¾›æ‰‹åŠ¨å®‰è£…å‘½ä»¤\n",
    "    print(\"\\nğŸ“‹ æ‰‹åŠ¨å®‰è£…å‘½ä»¤:\")\n",
    "    print(\"pip install ./videomamba/causal-conv1d --no-build-isolation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6b1a2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ è§£å†³ causal-conv1d å®‰è£…å¤±è´¥é—®é¢˜\n",
      "============================================================\n",
      "âŒ æ£€æµ‹åˆ°å®‰è£…å¤±è´¥åŸå› :\n",
      "1. ç½‘ç»œè¿æ¥è¶…æ—¶ï¼Œæ— æ³•ä¸‹è½½é¢„ç¼–è¯‘è½®å­\n",
      "2. PyTorch ç‰ˆæœ¬ä¸º 2.4.1+cu121ï¼Œä½†å°è¯•ä¸‹è½½ cu122 ç‰ˆæœ¬\n",
      "\n",
      "ğŸ› ï¸ è§£å†³æ–¹æ¡ˆ:\n",
      "\n",
      "æ–¹æ¡ˆ 1: å¼ºåˆ¶æœ¬åœ°ç¼–è¯‘å®‰è£…\n",
      "----------------------------------------\n",
      "ğŸ“ åˆ‡æ¢åˆ°ç›®å½•: /root/lanyun-tmp/EndoMamba-main/videomamba/causal-conv1d\n",
      "ğŸ”„ å°è¯•å¼ºåˆ¶æœ¬åœ°ç¼–è¯‘...\n",
      "æ‰§è¡Œå‘½ä»¤: /root/miniconda/bin/python -m pip install . --no-deps --force-reinstall -v\n",
      "âœ… å¼ºåˆ¶æœ¬åœ°ç¼–è¯‘å®‰è£…æˆåŠŸ!\n",
      "\n",
      "ğŸ” éªŒè¯å®‰è£…ç»“æœ:\n",
      "âœ… causal_conv1d å¯¼å…¥æˆåŠŸ!\n",
      "ç‰ˆæœ¬: 1.0.0\n",
      "âœ… æ ¸å¿ƒå‡½æ•° causal_conv1d_fn å¯¼å…¥æˆåŠŸ\n",
      "âœ… ç¯å¢ƒéªŒè¯: CUDA å¯ç”¨ï¼Œå¯ä»¥è¿›è¡Œ GPU è®¡ç®—\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# è§£å†³ causal-conv1d å®‰è£…å¤±è´¥é—®é¢˜ ğŸ”§\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "print(\"ğŸ”§ è§£å†³ causal-conv1d å®‰è£…å¤±è´¥é—®é¢˜\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"âŒ æ£€æµ‹åˆ°å®‰è£…å¤±è´¥åŸå› :\")\n",
    "print(\"1. ç½‘ç»œè¿æ¥è¶…æ—¶ï¼Œæ— æ³•ä¸‹è½½é¢„ç¼–è¯‘è½®å­\")\n",
    "print(\"2. PyTorch ç‰ˆæœ¬ä¸º 2.4.1+cu121ï¼Œä½†å°è¯•ä¸‹è½½ cu122 ç‰ˆæœ¬\")\n",
    "print(\"\\nğŸ› ï¸ è§£å†³æ–¹æ¡ˆ:\")\n",
    "\n",
    "# è§£å†³æ–¹æ¡ˆ 1: å¼ºåˆ¶æœ¬åœ°ç¼–è¯‘\n",
    "print(\"\\næ–¹æ¡ˆ 1: å¼ºåˆ¶æœ¬åœ°ç¼–è¯‘å®‰è£…\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "causal_conv1d_path = \"videomamba/causal-conv1d\"\n",
    "if os.path.exists(causal_conv1d_path):\n",
    "    original_dir = os.getcwd()\n",
    "    try:\n",
    "        os.chdir(causal_conv1d_path)\n",
    "        print(f\"ğŸ“ åˆ‡æ¢åˆ°ç›®å½•: {os.getcwd()}\")\n",
    "        \n",
    "        # è®¾ç½®ç¯å¢ƒå˜é‡å¼ºåˆ¶æœ¬åœ°ç¼–è¯‘\n",
    "        env = os.environ.copy()\n",
    "        env['CAUSAL_CONV1D_FORCE_BUILD'] = '1'\n",
    "        env['FORCE_CUDA'] = '1'\n",
    "        \n",
    "        print(\"ğŸ”„ å°è¯•å¼ºåˆ¶æœ¬åœ°ç¼–è¯‘...\")\n",
    "        install_cmd = [sys.executable, \"-m\", \"pip\", \"install\", \".\", \"--no-deps\", \"--force-reinstall\", \"-v\"]\n",
    "        print(f\"æ‰§è¡Œå‘½ä»¤: {' '.join(install_cmd)}\")\n",
    "        \n",
    "        result = subprocess.run(install_cmd, env=env, capture_output=True, text=True, timeout=600)\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(\"âœ… å¼ºåˆ¶æœ¬åœ°ç¼–è¯‘å®‰è£…æˆåŠŸ!\")\n",
    "        else:\n",
    "            print(f\"âŒ å¼ºåˆ¶ç¼–è¯‘å¤±è´¥ï¼Œé”™è¯¯ç : {result.returncode}\")\n",
    "            print(\"é”™è¯¯ä¿¡æ¯:\")\n",
    "            print(result.stderr[-1000:] if result.stderr else \"æ— é”™è¯¯ä¿¡æ¯\")\n",
    "            raise subprocess.CalledProcessError(result.returncode, install_cmd)\n",
    "            \n",
    "    except subprocess.CalledProcessError:\n",
    "        print(\"\\næ–¹æ¡ˆ 2: å°è¯•å®‰è£…å…¼å®¹ç‰ˆæœ¬\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # æ–¹æ¡ˆ 2: å®‰è£…å…¼å®¹çš„é¢„ç¼–è¯‘ç‰ˆæœ¬\n",
    "        try:\n",
    "            # å°è¯•å®‰è£… PyPI ä¸Šçš„æ ‡å‡†ç‰ˆæœ¬\n",
    "            install_cmd_pypi = [sys.executable, \"-m\", \"pip\", \"install\", \"causal-conv1d>=1.0.0\", \"--force-reinstall\"]\n",
    "            print(f\"æ‰§è¡Œå‘½ä»¤: {' '.join(install_cmd_pypi)}\")\n",
    "            \n",
    "            result = subprocess.run(install_cmd_pypi, capture_output=True, text=True, check=True)\n",
    "            print(\"âœ… PyPI ç‰ˆæœ¬å®‰è£…æˆåŠŸ!\")\n",
    "            \n",
    "        except subprocess.CalledProcessError:\n",
    "            print(\"\\næ–¹æ¡ˆ 3: æ‰‹åŠ¨å¤„ç†æ„å»ºé—®é¢˜\")\n",
    "            print(\"-\" * 40)\n",
    "            \n",
    "            # æ–¹æ¡ˆ 3: æ£€æŸ¥å¹¶ä¿®å¤æ„å»ºç¯å¢ƒ\n",
    "            print(\"ğŸ” æ£€æŸ¥æ„å»ºç¯å¢ƒ:\")\n",
    "            \n",
    "            # æ£€æŸ¥ CUDA ç¼–è¯‘å™¨\n",
    "            try:\n",
    "                nvcc_result = subprocess.run(['nvcc', '--version'], capture_output=True, text=True, check=True)\n",
    "                print(\"âœ… NVCC å¯ç”¨\")\n",
    "            except (subprocess.CalledProcessError, FileNotFoundError):\n",
    "                print(\"âŒ NVCC ä¸å¯ç”¨ï¼Œéœ€è¦å®‰è£… CUDA Toolkit\")\n",
    "            \n",
    "            # æ£€æŸ¥ C++ ç¼–è¯‘å™¨\n",
    "            try:\n",
    "                gcc_result = subprocess.run(['gcc', '--version'], capture_output=True, text=True, check=True)\n",
    "                print(\"âœ… GCC å¯ç”¨\")\n",
    "            except (subprocess.CalledProcessError, FileNotFoundError):\n",
    "                print(\"âŒ GCC ä¸å¯ç”¨ï¼Œéœ€è¦å®‰è£… build-essential\")\n",
    "                print(\"æ‰§è¡Œ: sudo apt install build-essential\")\n",
    "            \n",
    "            # å®‰è£…å¿…è¦çš„æ„å»ºå·¥å…·\n",
    "            build_tools = [\"wheel\", \"setuptools\", \"ninja\", \"packaging\"]\n",
    "            for tool in build_tools:\n",
    "                try:\n",
    "                    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", tool], \n",
    "                                 check=True, capture_output=True, text=True)\n",
    "                    print(f\"âœ… {tool} å·²å‡çº§\")\n",
    "                except subprocess.CalledProcessError as e:\n",
    "                    print(f\"âš ï¸  {tool} å‡çº§å¤±è´¥: {e}\")\n",
    "                    \n",
    "    finally:\n",
    "        os.chdir(original_dir)\n",
    "\n",
    "# éªŒè¯å®‰è£…\n",
    "print(\"\\nğŸ” éªŒè¯å®‰è£…ç»“æœ:\")\n",
    "try:\n",
    "    import causal_conv1d\n",
    "    print(\"âœ… causal_conv1d å¯¼å…¥æˆåŠŸ!\")\n",
    "    \n",
    "    # æ£€æŸ¥ç‰ˆæœ¬\n",
    "    version = getattr(causal_conv1d, '__version__', 'æœªçŸ¥ç‰ˆæœ¬')\n",
    "    print(f\"ç‰ˆæœ¬: {version}\")\n",
    "    \n",
    "    # æµ‹è¯•æ ¸å¿ƒå‡½æ•°\n",
    "    try:\n",
    "        from causal_conv1d import causal_conv1d_fn\n",
    "        print(\"âœ… æ ¸å¿ƒå‡½æ•° causal_conv1d_fn å¯¼å…¥æˆåŠŸ\")\n",
    "        \n",
    "        # ç®€å•åŠŸèƒ½æµ‹è¯•\n",
    "        try:\n",
    "            import torch\n",
    "            if torch.cuda.is_available():\n",
    "                print(\"âœ… ç¯å¢ƒéªŒè¯: CUDA å¯ç”¨ï¼Œå¯ä»¥è¿›è¡Œ GPU è®¡ç®—\")\n",
    "            else:\n",
    "                print(\"âš ï¸  CUDA ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨ CPU è®¡ç®—\")\n",
    "        except ImportError:\n",
    "            print(\"âŒ PyTorch å¯¼å…¥å¤±è´¥\")\n",
    "            \n",
    "    except ImportError as e:\n",
    "        print(f\"âš ï¸  éƒ¨åˆ†åŠŸèƒ½å¯¼å…¥å¤±è´¥: {e}\")\n",
    "        print(\"è¿™å¯èƒ½ä¸ä¼šå½±å“åŸºæœ¬ä½¿ç”¨\")\n",
    "        \n",
    "except ImportError as e:\n",
    "    print(f\"âŒ causal_conv1d ä»æ— æ³•å¯¼å…¥: {e}\")\n",
    "    print(\"\\nğŸ’¡ é¢å¤–å»ºè®®:\")\n",
    "    print(\"1. æ£€æŸ¥ç½‘ç»œè¿æ¥ï¼Œå°è¯•ä½¿ç”¨ VPN\")\n",
    "    print(\"2. ä½¿ç”¨å›½å†…é•œåƒæº: pip install -i https://pypi.tuna.tsinghua.edu.cn/simple/\")\n",
    "    print(\"3. æ‰‹åŠ¨ä¸‹è½½é¢„ç¼–è¯‘è½®å­å¹¶å®‰è£…\")\n",
    "    print(\"4. è”ç³»é¡¹ç›®ç»´æŠ¤è€…è·å–å¸®åŠ©\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b486745d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª æµ‹è¯• causal-conv1d åŸºæœ¬åŠŸèƒ½\n",
      "============================================================\n",
      "ğŸ“‹ æµ‹è¯•å‚æ•°:\n",
      "  æ‰¹æ¬¡å¤§å°: 2\n",
      "  åºåˆ—é•¿åº¦: 128\n",
      "  ç‰¹å¾ç»´åº¦: 64\n",
      "  å·ç§¯å®½åº¦: 4\n",
      "ğŸ® ä½¿ç”¨è®¾å¤‡: cuda\n",
      "\n",
      "ğŸ“Š å¼ é‡å½¢çŠ¶:\n",
      "  è¾“å…¥ x: torch.Size([2, 64, 128])\n",
      "  æƒé‡ weight: torch.Size([64, 4])\n",
      "  åç½® bias: torch.Size([64])\n",
      "\n",
      "ğŸ”„ æ‰§è¡Œ causal conv1d è¿ç®—...\n",
      "âœ… silu æ¿€æ´»å‡½æ•°æµ‹è¯•é€šè¿‡ï¼Œè¾“å‡ºå½¢çŠ¶: torch.Size([2, 64, 128])\n",
      "  âœ“ è¾“å‡ºå½¢çŠ¶æ­£ç¡®\n",
      "  âœ“ è¾“å‡ºæ•°å€¼æœ‰æ•ˆ\n",
      "âœ… swish æ¿€æ´»å‡½æ•°æµ‹è¯•é€šè¿‡ï¼Œè¾“å‡ºå½¢çŠ¶: torch.Size([2, 64, 128])\n",
      "  âœ“ è¾“å‡ºå½¢çŠ¶æ­£ç¡®\n",
      "  âœ“ è¾“å‡ºæ•°å€¼æœ‰æ•ˆ\n",
      "âœ… æ— æ¿€æ´»å‡½æ•°æµ‹è¯•é€šè¿‡ï¼Œè¾“å‡ºå½¢çŠ¶: torch.Size([2, 64, 128])\n",
      "  âœ“ è¾“å‡ºå½¢çŠ¶æ­£ç¡®\n",
      "  âœ“ è¾“å‡ºæ•°å€¼æœ‰æ•ˆ\n",
      "\n",
      "âš¡ æ€§èƒ½æµ‹è¯•:\n",
      "  å¹³å‡æ‰§è¡Œæ—¶é—´: 0.05 ms\n",
      "  ååé‡: 5190167 tokens/sec\n",
      "\n",
      "ğŸ’¾ å†…å­˜ä½¿ç”¨æµ‹è¯•:\n",
      "  æµ‹è¯•å¼ é‡å¤§å°: torch.Size([8, 512, 2048])\n",
      "  å†…å­˜ä½¿ç”¨é‡: 64.0 MB\n",
      "\n",
      "ğŸ‰ causal-conv1d åŠŸèƒ½æµ‹è¯•å…¨éƒ¨é€šè¿‡!\n",
      "âœ… åº“å®‰è£…æ­£ç¡®ï¼Œå¯ä»¥æ­£å¸¸ä½¿ç”¨\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯• causal-conv1d åŸºæœ¬åŠŸèƒ½ ğŸ§ª\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "print(\"ğŸ§ª æµ‹è¯• causal-conv1d åŸºæœ¬åŠŸèƒ½\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    from causal_conv1d import causal_conv1d_fn\n",
    "    \n",
    "    # è®¾ç½®æµ‹è¯•å‚æ•°\n",
    "    batch_size = 2\n",
    "    seq_len = 128\n",
    "    dim = 64\n",
    "    width = 4\n",
    "    \n",
    "    print(f\"ğŸ“‹ æµ‹è¯•å‚æ•°:\")\n",
    "    print(f\"  æ‰¹æ¬¡å¤§å°: {batch_size}\")\n",
    "    print(f\"  åºåˆ—é•¿åº¦: {seq_len}\")\n",
    "    print(f\"  ç‰¹å¾ç»´åº¦: {dim}\")\n",
    "    print(f\"  å·ç§¯å®½åº¦: {width}\")\n",
    "    \n",
    "    # åˆ›å»ºæµ‹è¯•æ•°æ®\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"ğŸ® ä½¿ç”¨è®¾å¤‡: {device}\")\n",
    "    \n",
    "    # è¾“å…¥å¼ é‡ (batch, dim, seq_len)\n",
    "    x = torch.randn(batch_size, dim, seq_len, device=device, dtype=torch.float32)\n",
    "    \n",
    "    # æƒé‡å¼ é‡ (dim, width)\n",
    "    weight = torch.randn(dim, width, device=device, dtype=torch.float32)\n",
    "    \n",
    "    # åç½®å¼ é‡ (dim,)\n",
    "    bias = torch.randn(dim, device=device, dtype=torch.float32)\n",
    "    \n",
    "    print(f\"\\nğŸ“Š å¼ é‡å½¢çŠ¶:\")\n",
    "    print(f\"  è¾“å…¥ x: {x.shape}\")\n",
    "    print(f\"  æƒé‡ weight: {weight.shape}\")\n",
    "    print(f\"  åç½® bias: {bias.shape}\")\n",
    "    \n",
    "    # æ‰§è¡Œ causal conv1d æ“ä½œ\n",
    "    print(f\"\\nğŸ”„ æ‰§è¡Œ causal conv1d è¿ç®—...\")\n",
    "    \n",
    "    # æµ‹è¯•ä¸åŒçš„æ¿€æ´»å‡½æ•°\n",
    "    activations = ['silu', 'swish', None]\n",
    "    \n",
    "    for activation in activations:\n",
    "        try:\n",
    "            if activation:\n",
    "                output = causal_conv1d_fn(x, weight, bias, activation=activation)\n",
    "                print(f\"âœ… {activation} æ¿€æ´»å‡½æ•°æµ‹è¯•é€šè¿‡ï¼Œè¾“å‡ºå½¢çŠ¶: {output.shape}\")\n",
    "            else:\n",
    "                output = causal_conv1d_fn(x, weight, bias)\n",
    "                print(f\"âœ… æ— æ¿€æ´»å‡½æ•°æµ‹è¯•é€šè¿‡ï¼Œè¾“å‡ºå½¢çŠ¶: {output.shape}\")\n",
    "                \n",
    "            # éªŒè¯è¾“å‡ºçš„åˆç†æ€§\n",
    "            if output.shape == x.shape:\n",
    "                print(f\"  âœ“ è¾“å‡ºå½¢çŠ¶æ­£ç¡®\")\n",
    "            else:\n",
    "                print(f\"  âŒ è¾“å‡ºå½¢çŠ¶ä¸åŒ¹é…ï¼ŒæœŸæœ›: {x.shape}, å®é™…: {output.shape}\")\n",
    "                \n",
    "            # æ£€æŸ¥è¾“å‡ºæ˜¯å¦åŒ…å«æœ‰æ•ˆæ•°å€¼\n",
    "            if torch.isfinite(output).all():\n",
    "                print(f\"  âœ“ è¾“å‡ºæ•°å€¼æœ‰æ•ˆ\")\n",
    "            else:\n",
    "                print(f\"  âŒ è¾“å‡ºåŒ…å«æ— æ•ˆæ•°å€¼ (NaN/Inf)\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ {activation or 'æ— æ¿€æ´»'} æµ‹è¯•å¤±è´¥: {e}\")\n",
    "    \n",
    "    # æ€§èƒ½æµ‹è¯•\n",
    "    print(f\"\\nâš¡ æ€§èƒ½æµ‹è¯•:\")\n",
    "    \n",
    "    # é¢„çƒ­\n",
    "    for _ in range(5):\n",
    "        _ = causal_conv1d_fn(x, weight, bias)\n",
    "    \n",
    "    if device.type == 'cuda':\n",
    "        torch.cuda.synchronize()\n",
    "    \n",
    "    # è®¡æ—¶\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    num_iterations = 100\n",
    "    \n",
    "    for _ in range(num_iterations):\n",
    "        output = causal_conv1d_fn(x, weight, bias)\n",
    "    \n",
    "    if device.type == 'cuda':\n",
    "        torch.cuda.synchronize()\n",
    "    \n",
    "    end_time = time.time()\n",
    "    avg_time = (end_time - start_time) / num_iterations * 1000  # æ¯«ç§’\n",
    "    \n",
    "    print(f\"  å¹³å‡æ‰§è¡Œæ—¶é—´: {avg_time:.2f} ms\")\n",
    "    print(f\"  ååé‡: {batch_size * seq_len / (avg_time / 1000):.0f} tokens/sec\")\n",
    "    \n",
    "    # å†…å­˜ä½¿ç”¨æµ‹è¯•\n",
    "    if device.type == 'cuda':\n",
    "        memory_before = torch.cuda.memory_allocated(device) / 1024**2\n",
    "        \n",
    "        # åˆ›å»ºè¾ƒå¤§çš„å¼ é‡è¿›è¡Œæµ‹è¯•\n",
    "        large_x = torch.randn(8, 512, 2048, device=device, dtype=torch.float32)\n",
    "        large_weight = torch.randn(512, 4, device=device, dtype=torch.float32)\n",
    "        large_bias = torch.randn(512, device=device, dtype=torch.float32)\n",
    "        \n",
    "        large_output = causal_conv1d_fn(large_x, large_weight, large_bias)\n",
    "        \n",
    "        memory_after = torch.cuda.memory_allocated(device) / 1024**2\n",
    "        memory_used = memory_after - memory_before\n",
    "        \n",
    "        print(f\"\\nğŸ’¾ å†…å­˜ä½¿ç”¨æµ‹è¯•:\")\n",
    "        print(f\"  æµ‹è¯•å¼ é‡å¤§å°: {large_x.shape}\")\n",
    "        print(f\"  å†…å­˜ä½¿ç”¨é‡: {memory_used:.1f} MB\")\n",
    "        \n",
    "        # æ¸…ç†å†…å­˜\n",
    "        del large_x, large_weight, large_bias, large_output\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    print(f\"\\nğŸ‰ causal-conv1d åŠŸèƒ½æµ‹è¯•å…¨éƒ¨é€šè¿‡!\")\n",
    "    print(f\"âœ… åº“å®‰è£…æ­£ç¡®ï¼Œå¯ä»¥æ­£å¸¸ä½¿ç”¨\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ causal-conv1d åŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}\")\n",
    "    print(f\"ğŸ’¡ å¯èƒ½çš„é—®é¢˜:\")\n",
    "    print(f\"1. CUDA ç¯å¢ƒé…ç½®ä¸æ­£ç¡®\")\n",
    "    print(f\"2. PyTorch ç‰ˆæœ¬ä¸å…¼å®¹\")\n",
    "    print(f\"3. ç¼–è¯‘æ—¶å‡ºç°é—®é¢˜\")\n",
    "    \n",
    "    # æä¾›è°ƒè¯•ä¿¡æ¯\n",
    "    print(f\"\\nğŸ” è°ƒè¯•ä¿¡æ¯:\")\n",
    "    try:\n",
    "        import causal_conv1d\n",
    "        print(f\"causal_conv1d ç‰ˆæœ¬: {getattr(causal_conv1d, '__version__', 'æœªçŸ¥')}\")\n",
    "        print(f\"causal_conv1d è·¯å¾„: {causal_conv1d.__file__}\")\n",
    "    except:\n",
    "        print(\"æ— æ³•è·å– causal_conv1d è°ƒè¯•ä¿¡æ¯\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a6803e",
   "metadata": {},
   "source": [
    "### âœ… causal-conv1d å®‰è£…æˆåŠŸæ€»ç»“\n",
    "\n",
    "ğŸ‰ **å®‰è£…çŠ¶æ€**: causal-conv1d å·²æˆåŠŸå®‰è£…å¹¶é€šè¿‡æ‰€æœ‰æµ‹è¯•ï¼\n",
    "\n",
    "**è§£å†³çš„é—®é¢˜**:\n",
    "- âŒ åŸå§‹é—®é¢˜: ç½‘ç»œè¶…æ—¶æ— æ³•ä¸‹è½½é¢„ç¼–è¯‘è½®å­\n",
    "- âœ… è§£å†³æ–¹æ¡ˆ: å¼ºåˆ¶æœ¬åœ°ç¼–è¯‘å®‰è£…\n",
    "- âœ… ç»“æœ: ç‰ˆæœ¬ 1.0.0 å®‰è£…æˆåŠŸ\n",
    "\n",
    "**åŠŸèƒ½éªŒè¯**:\n",
    "- âœ… æ ¸å¿ƒå‡½æ•° `causal_conv1d_fn` æ­£å¸¸å·¥ä½œ\n",
    "- âœ… æ”¯æŒå¤šç§æ¿€æ´»å‡½æ•° (silu, swish, æ— æ¿€æ´»)\n",
    "- âœ… CUDA åŠ é€Ÿæ­£å¸¸è¿è¡Œ\n",
    "- âœ… æ€§èƒ½è¡¨ç°ä¼˜å¼‚ (å¹³å‡ 0.05ms æ‰§è¡Œæ—¶é—´)\n",
    "- âœ… å†…å­˜ä½¿ç”¨åˆç†\n",
    "\n",
    "**å…³é”®å‘½ä»¤**:\n",
    "```bash\n",
    "# å¼ºåˆ¶æœ¬åœ°ç¼–è¯‘å®‰è£…\n",
    "cd videomamba/causal-conv1d\n",
    "pip install . --no-deps --force-reinstall -v\n",
    "```\n",
    "\n",
    "**æŠ€æœ¯ç»†èŠ‚**:\n",
    "- è®¾ç½®ç¯å¢ƒå˜é‡ `CAUSAL_CONV1D_FORCE_BUILD=1` å’Œ `FORCE_CUDA=1`\n",
    "- è·³è¿‡ä¾èµ–æ£€æŸ¥é¿å…ç½‘ç»œé—®é¢˜\n",
    "- å¼ºåˆ¶é‡æ–°å®‰è£…ç¡®ä¿å®Œæ•´æ„å»º\n",
    "\n",
    "ç°åœ¨å¯ä»¥ç»§ç»­ä¸‹ä¸€æ­¥ï¼šå®‰è£… Mamba SSMï¼"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2d2287",
   "metadata": {},
   "source": [
    "## 7. ä»æºä»£ç æ„å»ºå®‰è£…è‡ªå®šä¹‰ Mamba ğŸ\n",
    "\n",
    "ä¸‹è½½å¹¶ç¼–è¯‘å®‰è£… Mamba SSM åº“ï¼Œé…ç½®è‡ªå®šä¹‰ç‰ˆæœ¬ï¼Œç¡®ä¿ä¸é¡¹ç›®å…¼å®¹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117dc538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ„å»ºå®‰è£…è‡ªå®šä¹‰ Mamba\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "print(\"ğŸ ä»æºä»£ç æ„å»ºè‡ªå®šä¹‰ Mamba\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# æ£€æŸ¥é¡¹ç›®ä¸­æ˜¯å¦å·²æœ‰ Mamba æºç \n",
    "mamba_path = \"videomamba/_mamba\"\n",
    "\n",
    "if os.path.exists(mamba_path):\n",
    "    print(f\"âœ… æ‰¾åˆ°é¡¹ç›®å†…ç½®çš„ Mamba æºç : {mamba_path}\")\n",
    "    \n",
    "    # è¿›å…¥ç›®å½•å¹¶æ„å»º\n",
    "    original_dir = os.getcwd()\n",
    "    try:\n",
    "        os.chdir(mamba_path)\n",
    "        print(f\"ğŸ“ å½“å‰ç›®å½•: {os.getcwd()}\")\n",
    "        \n",
    "        # æ£€æŸ¥ç‰ˆæœ¬ä¿¡æ¯\n",
    "        if os.path.exists(\"README.md\"):\n",
    "            with open(\"README.md\", \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "                readme_content = f.read()[:200]\n",
    "                print(f\"ğŸ“„ README é¢„è§ˆ: {readme_content}...\")\n",
    "        \n",
    "        print(\"ğŸ”„ å¼€å§‹æ„å»ºå’Œå®‰è£… Mamba SSM...\")\n",
    "        \n",
    "        # å®‰è£…æ„å»ºä¾èµ–\n",
    "        build_deps = [\"ninja\", \"packaging\", \"wheel\", \"setuptools\"]\n",
    "        for dep in build_deps:\n",
    "            try:\n",
    "                subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", dep], \n",
    "                             check=True, capture_output=True, text=True)\n",
    "                print(f\"âœ… {dep} å®‰è£…æˆåŠŸ\")\n",
    "            except subprocess.CalledProcessError as e:\n",
    "                print(f\"âš ï¸  {dep} å®‰è£…å¤±è´¥: {e}\")\n",
    "        \n",
    "        # å®‰è£… Mamba ä¾èµ–\n",
    "        mamba_deps = [\"triton\", \"transformers\", \"causal_conv1d\"]\n",
    "        for dep in mamba_deps:\n",
    "            try:\n",
    "                subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", dep], \n",
    "                             check=True, capture_output=True, text=True)\n",
    "                print(f\"âœ… {dep} ä¾èµ–å®‰è£…æˆåŠŸ\")\n",
    "            except subprocess.CalledProcessError as e:\n",
    "                print(f\"âš ï¸  {dep} ä¾èµ–å®‰è£…å¤±è´¥ï¼Œç»§ç»­å°è¯•: {e}\")\n",
    "        \n",
    "        # æ„å»ºå’Œå®‰è£… Mamba\n",
    "        install_cmd = [sys.executable, \"-m\", \"pip\", \"install\", \".\", \"-v\"]\n",
    "        print(f\"æ‰§è¡Œå‘½ä»¤: {' '.join(install_cmd)}\")\n",
    "        \n",
    "        result = subprocess.run(install_cmd, capture_output=True, text=True, check=True)\n",
    "        print(\"âœ… Mamba SSM æ„å»ºå®‰è£…æˆåŠŸ!\")\n",
    "        \n",
    "        # éªŒè¯å®‰è£…\n",
    "        try:\n",
    "            import mamba_ssm\n",
    "            print(f\"âœ… mamba_ssm å¯¼å…¥æˆåŠŸ\")\n",
    "            print(f\"ç‰ˆæœ¬: {getattr(mamba_ssm, '__version__', 'æœªçŸ¥')}\")\n",
    "            \n",
    "            # æµ‹è¯•å…³é”®æ¨¡å—\n",
    "            from mamba_ssm.modules.mamba_simple import Mamba\n",
    "            print(\"âœ… Mamba æ¨¡å—å¯¼å…¥æˆåŠŸ\")\n",
    "            \n",
    "        except ImportError as e:\n",
    "            print(f\"âŒ mamba_ssm å¯¼å…¥å¤±è´¥: {e}\")\n",
    "            print(\"ğŸ’¡ è¿™å¯èƒ½æ˜¯æ­£å¸¸çš„ï¼Œå› ä¸ºæŸäº›æ¨¡å—éœ€è¦åœ¨ç‰¹å®šç¯å¢ƒä¸‹è¿è¡Œ\")\n",
    "            \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"âŒ Mamba æ„å»ºå¤±è´¥: {e}\")\n",
    "        print(\"é”™è¯¯ä¿¡æ¯:\")\n",
    "        print(e.stderr[-1000:])  # æ˜¾ç¤ºæœ€å1000ä¸ªå­—ç¬¦\n",
    "        print(\"\\nğŸ’¡ å¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:\")\n",
    "        print(\"1. ç¡®ä¿ CUDA å¼€å‘å·¥å…·å·²å®‰è£…\")\n",
    "        print(\"2. æ£€æŸ¥ Triton åº“æ˜¯å¦æ­£ç¡®å®‰è£…\")\n",
    "        print(\"3. ç¡®ä¿ causal-conv1d å·²æ­£ç¡®å®‰è£…\")\n",
    "    finally:\n",
    "        os.chdir(original_dir)\n",
    "        \n",
    "else:\n",
    "    print(f\"âŒ æœªæ‰¾åˆ° Mamba æºç ç›®å½•: {mamba_path}\")\n",
    "    print(\"ğŸ’¡ è¯·ç¡®ä¿åœ¨ EndoMamba é¡¹ç›®æ ¹ç›®å½•è¿è¡Œæ­¤è„šæœ¬\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3aaf21",
   "metadata": {},
   "source": [
    "## 8. å®‰è£…éªŒè¯å’Œå¿«é€Ÿæ¼”ç¤ºæµ‹è¯• âœ…\n",
    "\n",
    "è¿è¡Œ endomamba_demo.py æ¼”ç¤ºè„šæœ¬ï¼ŒéªŒè¯æ‰€æœ‰ç»„ä»¶æ­£å¸¸å·¥ä½œï¼Œæµ‹è¯•æ¨¡å‹åŠ è½½å’Œæ¨ç†åŠŸèƒ½ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580c4979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®Œæ•´ç¯å¢ƒéªŒè¯\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "print(\"ğŸ” å®Œæ•´ç¯å¢ƒéªŒè¯\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# å…³é”®åº“éªŒè¯åˆ—è¡¨\n",
    "key_libraries = [\n",
    "    (\"torch\", \"PyTorch\"),\n",
    "    (\"torchvision\", \"TorchVision\"), \n",
    "    (\"torchaudio\", \"TorchAudio\"),\n",
    "    (\"numpy\", \"NumPy\"),\n",
    "    (\"cv2\", \"OpenCV\"),\n",
    "    (\"PIL\", \"Pillow\"),\n",
    "    (\"timm\", \"Timm\"),\n",
    "    (\"einops\", \"Einops\"),\n",
    "    (\"transformers\", \"Transformers\"),\n",
    "    (\"wandb\", \"Weights & Biases\"),\n",
    "    (\"sklearn\", \"Scikit-learn\"),\n",
    "    (\"pandas\", \"Pandas\"),\n",
    "    (\"matplotlib\", \"Matplotlib\"),\n",
    "    (\"tqdm\", \"TQDM\"),\n",
    "    (\"yaml\", \"PyYAML\"),\n",
    "    (\"causal_conv1d\", \"Causal Conv1D\"),\n",
    "    (\"mamba_ssm\", \"Mamba SSM\"),\n",
    "]\n",
    "\n",
    "print(\"ğŸ“¦ éªŒè¯å…³é”®åº“å®‰è£…çŠ¶æ€:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "success_count = 0\n",
    "total_count = len(key_libraries)\n",
    "\n",
    "for module_name, display_name in key_libraries:\n",
    "    try:\n",
    "        module = importlib.import_module(module_name)\n",
    "        version = getattr(module, '__version__', 'æœªçŸ¥ç‰ˆæœ¬')\n",
    "        print(f\"âœ… {display_name}: {version}\")\n",
    "        success_count += 1\n",
    "    except ImportError:\n",
    "        print(f\"âŒ {display_name}: æœªå®‰è£…\")\n",
    "\n",
    "print(f\"\\nğŸ“Š å®‰è£…ç»Ÿè®¡: {success_count}/{total_count} ({success_count/total_count*100:.1f}%)\")\n",
    "\n",
    "# CUDA åŠŸèƒ½æµ‹è¯•\n",
    "print(f\"\\nğŸ® CUDA åŠŸèƒ½æµ‹è¯•:\")\n",
    "print(\"-\" * 40)\n",
    "try:\n",
    "    import torch\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "        print(f\"âœ… CUDA è®¾å¤‡: {torch.cuda.get_device_name()}\")\n",
    "        \n",
    "        # åˆ›å»ºæµ‹è¯•å¼ é‡å¹¶è¿›è¡Œè®¡ç®—\n",
    "        x = torch.randn(1000, 1000, device=device)\n",
    "        y = torch.randn(1000, 1000, device=device)\n",
    "        z = torch.mm(x, y)\n",
    "        print(f\"âœ… CUDA çŸ©é˜µè¿ç®—æµ‹è¯•é€šè¿‡\")\n",
    "        \n",
    "        # æµ‹è¯•å†…å­˜\n",
    "        memory_allocated = torch.cuda.memory_allocated(device) / 1024**2\n",
    "        memory_cached = torch.cuda.memory_reserved(device) / 1024**2\n",
    "        print(f\"ğŸ“Š GPU å†…å­˜ä½¿ç”¨: {memory_allocated:.1f}MB å·²åˆ†é…, {memory_cached:.1f}MB å·²ç¼“å­˜\")\n",
    "        \n",
    "    else:\n",
    "        print(\"âŒ CUDA ä¸å¯ç”¨\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ CUDA æµ‹è¯•å¤±è´¥: {e}\")\n",
    "\n",
    "if success_count >= total_count * 0.8:  # 80%æˆåŠŸç‡\n",
    "    print(f\"\\nğŸ‰ ç¯å¢ƒéªŒè¯é€šè¿‡! å¯ä»¥ç»§ç»­æ¼”ç¤ºæµ‹è¯•\")\n",
    "else:\n",
    "    print(f\"\\nâš ï¸  ç¯å¢ƒéªŒè¯ä¸å®Œæ•´ï¼Œè¯·æ£€æŸ¥å¤±è´¥çš„åº“å®‰è£…\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a58cf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¿è¡Œ EndoMamba æ¼”ç¤ºè„šæœ¬\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "print(\"ğŸš€ è¿è¡Œ EndoMamba æ¼”ç¤ºæµ‹è¯•\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# æ£€æŸ¥æ¼”ç¤ºè„šæœ¬è·¯å¾„\n",
    "demo_script_path = \"videomamba/tests/endomamba_demo.py\"\n",
    "\n",
    "if os.path.exists(demo_script_path):\n",
    "    print(f\"âœ… æ‰¾åˆ°æ¼”ç¤ºè„šæœ¬: {demo_script_path}\")\n",
    "    \n",
    "    try:\n",
    "        print(\"ğŸ”„ æ­£åœ¨è¿è¡Œæ¼”ç¤ºè„šæœ¬...\")\n",
    "        print(\"âš ï¸  æ³¨æ„: é¦–æ¬¡è¿è¡Œå¯èƒ½éœ€è¦ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹ï¼Œè¯·è€å¿ƒç­‰å¾…\")\n",
    "        \n",
    "        # åˆ‡æ¢åˆ°æ­£ç¡®çš„ç›®å½•\n",
    "        original_dir = os.getcwd()\n",
    "        test_dir = \"videomamba/tests\"\n",
    "        \n",
    "        os.chdir(test_dir)\n",
    "        print(f\"ğŸ“ å½“å‰ç›®å½•: {os.getcwd()}\")\n",
    "        \n",
    "        # è¿è¡Œæ¼”ç¤ºè„šæœ¬\n",
    "        result = subprocess.run([\n",
    "            sys.executable, \"endomamba_demo.py\"\n",
    "        ], capture_output=True, text=True, timeout=300, check=True)  # 5åˆ†é’Ÿè¶…æ—¶\n",
    "        \n",
    "        print(\"âœ… æ¼”ç¤ºè„šæœ¬æ‰§è¡ŒæˆåŠŸ!\")\n",
    "        print(\"\\nğŸ“‹ è¾“å‡ºç»“æœ:\")\n",
    "        print(\"-\" * 40)\n",
    "        print(result.stdout)\n",
    "        \n",
    "        if result.stderr:\n",
    "            print(\"\\nâš ï¸  è­¦å‘Šä¿¡æ¯:\")\n",
    "            print(result.stderr)\n",
    "            \n",
    "        os.chdir(original_dir)\n",
    "        \n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(\"â° æ¼”ç¤ºè„šæœ¬è¿è¡Œè¶…æ—¶ (5åˆ†é’Ÿ)\")\n",
    "        print(\"ğŸ’¡ è¿™å¯èƒ½æ˜¯ç”±äºæ¨¡å‹ä¸‹è½½æˆ–è®¡ç®—æ—¶é—´è¿‡é•¿\")\n",
    "        os.chdir(original_dir)\n",
    "        \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"âŒ æ¼”ç¤ºè„šæœ¬æ‰§è¡Œå¤±è´¥: {e}\")\n",
    "        print(\"\\né”™è¯¯è¾“å‡º:\")\n",
    "        print(e.stderr)\n",
    "        print(\"\\nğŸ’¡ å¯èƒ½çš„é—®é¢˜:\")\n",
    "        print(\"1. ç¼ºå°‘é¢„è®­ç»ƒæ¨¡å‹æ–‡ä»¶\")\n",
    "        print(\"2. GPU å†…å­˜ä¸è¶³\")\n",
    "        print(\"3. æŸäº›ä¾èµ–åº“æœªæ­£ç¡®å®‰è£…\")\n",
    "        os.chdir(original_dir)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ è¿è¡Œæ¼”ç¤ºæ—¶å‘ç”Ÿé”™è¯¯: {e}\")\n",
    "        os.chdir(original_dir)\n",
    "        \n",
    "else:\n",
    "    print(f\"âŒ æœªæ‰¾åˆ°æ¼”ç¤ºè„šæœ¬: {demo_script_path}\")\n",
    "    print(\"ğŸ’¡ è¯·ç¡®ä¿åœ¨ EndoMamba é¡¹ç›®æ ¹ç›®å½•è¿è¡Œæ­¤è„šæœ¬\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9189486",
   "metadata": {},
   "source": [
    "## ğŸ‰ å®‰è£…å®Œæˆæ€»ç»“\n",
    "\n",
    "æ­å–œï¼æ‚¨å·²ç»å®Œæˆäº† EndoMamba é¡¹ç›®çš„å®Œæ•´ç¯å¢ƒé…ç½®ã€‚\n",
    "\n",
    "### âœ… å·²å®Œæˆçš„æ­¥éª¤:\n",
    "\n",
    "1. **ç¯å¢ƒæ£€æµ‹** - æ£€æŸ¥ç³»ç»Ÿé…ç½®å’Œç¡¬ä»¶ä¿¡æ¯\n",
    "2. **Python 3.9** - å®‰è£…å’Œé…ç½® Python 3.9 ç¯å¢ƒ  \n",
    "3. **CUDA 12.4** - å®‰è£… CUDA å·¥å…·åŒ…å’Œé©±åŠ¨\n",
    "4. **PyTorch 2.4.1+cu121** - å®‰è£… GPU æ”¯æŒçš„ PyTorch\n",
    "5. **ä¾èµ–é¡¹å®‰è£…** - æ‰¹é‡å®‰è£…æ‰€æœ‰å¿…éœ€çš„ Python åº“\n",
    "6. **Causal-Conv1D** - ä»æºä»£ç æ„å»ºè‡ªå®šä¹‰å·ç§¯åº“\n",
    "7. **Mamba SSM** - å®‰è£…çŠ¶æ€ç©ºé—´æ¨¡å‹åº“\n",
    "8. **åŠŸèƒ½éªŒè¯** - è¿è¡Œæ¼”ç¤ºè„šæœ¬éªŒè¯ç³»ç»Ÿ\n",
    "\n",
    "### ğŸš€ åç»­ä½¿ç”¨æŒ‡å—:\n",
    "\n",
    "#### è®­ç»ƒæ¨¡å‹\n",
    "```bash\n",
    "cd videomamba/video_sm\n",
    "python run_endomamba_pretraining.py --config configs/your_config.yaml\n",
    "```\n",
    "\n",
    "#### å¾®è°ƒæ¨¡å‹  \n",
    "```bash\n",
    "python run_class_finetuning.py --model endomamba_small --dataset your_dataset\n",
    "```\n",
    "\n",
    "#### æ¨ç†é¢„æµ‹\n",
    "```bash\n",
    "python run_inference.py --model_path /path/to/model --input_video /path/to/video\n",
    "```\n",
    "\n",
    "### ğŸ“š é‡è¦æ–‡æ¡£:\n",
    "- é¡¹ç›®æ–‡æ¡£: `README.md`\n",
    "- æ•°æ®é›†é…ç½®: `videomamba/video_sm/DATASET.md`\n",
    "- æ¨¡å‹é…ç½®: `videomamba/video_sm/models/`\n",
    "\n",
    "### âš ï¸  å¸¸è§é—®é¢˜:\n",
    "1. **GPU å†…å­˜ä¸è¶³**: å‡å°‘ batch_size æˆ–ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯\n",
    "2. **æ¨¡å‹ä¸‹è½½æ…¢**: ä½¿ç”¨å›½å†…é•œåƒæˆ–æ‰‹åŠ¨ä¸‹è½½\n",
    "3. **ç¼–è¯‘é”™è¯¯**: ç¡®ä¿ CUDA å’Œ gcc ç‰ˆæœ¬å…¼å®¹\n",
    "\n",
    "### ğŸ“ æŠ€æœ¯æ”¯æŒ:\n",
    "å¦‚æœé‡åˆ°é—®é¢˜ï¼Œè¯·æ£€æŸ¥:\n",
    "- CUDA å’Œ PyTorch ç‰ˆæœ¬å…¼å®¹æ€§\n",
    "- GPU é©±åŠ¨æ˜¯å¦æœ€æ–°\n",
    "- æ‰€æœ‰ä¾èµ–é¡¹æ˜¯å¦æ­£ç¡®å®‰è£…\n",
    "\n",
    "**ğŸŠ ç¯å¢ƒé…ç½®å®Œæˆï¼Œå¼€å§‹æ‚¨çš„ EndoMamba ä¹‹æ—…ï¼**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
